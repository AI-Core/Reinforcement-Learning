{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to RL \n",
    "\n",
    "## Problem setup: We want to make an AI that is able to complete a simple video game.\n",
    "\n",
    "### What is the game we are going to start with?\n",
    "In this game, we want our agent (character) to move through the 2D world and reach the goal. At each timestep our agent can to either move up, down, left or right. The agent cannot move into obstacles, and when it reaches the goal, the game ends.\n",
    "\n",
    "# insert video of game being played\n",
    "\n",
    "We are going to use an environment that we built, called Griddy, that works in exactly the same way as other environments provided as part of openAI gym. \n",
    "\n",
    "\n",
    "The main ideas are:\n",
    "<ul>\n",
    "<li>we need to create our environment</li>\n",
    "<li>we need to initialise it by calling `env.reset()`</li>\n",
    "<li>we can increment the simulation by one timestep by calling `env.step(action)`</li>\n",
    "</ul>\n",
    "\n",
    "Check out [openAI gym's docs](http://gym.openai.com/docs/) to see how the environments work in general and in more detail.\n",
    "\n",
    "Let's set up our simulation to train our agent in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from GriddyEnv import GriddyEnv # make sure you: pip3 install GriddyEnv\n",
    "\n",
    "# SET UP THE ENVIRONMENT\n",
    "env = GriddyEnv()    # create the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once we have an agent in the game, what do we do?\n",
    "\n",
    "Our agent has no idea of how to win the game. It simply observes states that change based on it's actions and receives a reward signal for doing so.\n",
    "So the agent has to learn about the game for itself. Just like a baby learns to interact with it's world by playing with it, our agent has to try random actions to figure out when and why it receives negative or positive rewards.\n",
    "\n",
    "A function which tells the agent what to do in a given state is called a **policy**\n",
    "\n",
    "We need our agent to understand what actions might lead it to achieving high rewards, but it doesn't know anything about how to complete the game yet. So let's set up our environment and implement a random policy that takes in a state and returns a random action for the agent to take.\n",
    "\n",
    "![](./images/policy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Space\n",
    "The action space consists of 4 unique actions: 0, 1, 2, 3<br>\n",
    "0 - Move left<br>\n",
    "1 - Move right<br>\n",
    "2 - Move up<br>\n",
    "3 - Move down<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation Space\n",
    "Has shape (3, 4, 4). Our grid world is 4x4<br>\n",
    "Each of the 3 channels is a binary mask for the location of different objects within the environment.<br>\n",
    "Channel 0 - Goal<br>\n",
    "Channel 1 - Wall<br>\n",
    "Channel 2 - Agent<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise agent function\n",
    "def visualise_agent(policy, n=5):\n",
    "    try:\n",
    "        for trial_i in range(n):\n",
    "            observation = env.reset()\n",
    "            done=False\n",
    "            t=0\n",
    "            while not done:\n",
    "                env.render()\n",
    "                policy_action = policy(observation)\n",
    "                observation, reward, done, info = env.step(policy_action)\n",
    "                time.sleep(0.5)\n",
    "                t+=1\n",
    "            env.render()\n",
    "            time.sleep(1.5)\n",
    "            print(\"Episode {} finished after {} timesteps\".format(trial_i, t))\n",
    "        env.close()\n",
    "    except KeyboardInterrupt:\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENT A RANDOM POLICY\n",
    "def random_policy(state):\n",
    "    #action = #fill this in\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## How do we know if we are doing well?\n",
    "\n",
    "When our agent takes this action and moves into a new state, the environment returns it a reward. The reward when it reaches the goal is +1, and 0 everywhere else. The reward that the agent receives at any point can be considered as what it feels in that moment - like pain or pleasure.\n",
    "\n",
    "**However**, the reward doesn't tell the agent how good that move actually was, only whether it sensed anything, and how good or bad that sensation was.\n",
    "\n",
    "E.g.\n",
    "- Our agent might not receive any reward for stepping toward the goal, even though this might be a good move.\n",
    "- A robot might receive a negative reward as it's battery depletes, but still make good progress towards its goal.\n",
    "- A chess playing agent might receive a positive reward for taking an opponent's piece, but make a bad move in doing so by exposing its king to an attack eventually causing it to lose the game.\n",
    "\n",
    "What we really want to know is not the instantaneous reward, but \"How good is the position I'm in right now?\", that is, what amount of reward can our agent get from this point onwards.\n",
    "This future reward is also known as the return.\n",
    "\n",
    "![](./images/undiscounted_return.png)\n",
    "\n",
    "#### Is getting a reward now as good as getting the same reward later?\n",
    "- What if the reward is removed from the game in the next timestep?\n",
    "- Would you rather be rich now or later?\n",
    "- What if a larger reward is introduced and you don't have enough energy to reach both?\n",
    "- What about inflation?\n",
    "\n",
    "It's better to get rewards sooner rather than later.\n",
    "\n",
    "![](./images/decay.png)\n",
    "\n",
    "We can encode this into our goal by using a **discount factor**, $\\gamma \\in [0, 1]$ ($\\gamma$ between 0 and 1). This makes our agent value more immediate rewards more than those which can be reached further in the future. This makes the goal become:\n",
    "\n",
    "![](./images/discounted_return.png)\n",
    "\n",
    "\n",
    "The value of these return values can be defined recursively as shown below.\n",
    "\n",
    "![](./images/recursive_return.png)\n",
    "\n",
    "Because of this, we can calculate the returns by having our agent play one run-through of the game and then *backing-up* through that trajectory, step-by-step, looking forward at what the future reward was from that point.\n",
    "\n",
    "The back up procedure is a way that we can determine the returns for each state that we visited in an episode. The return of a terminal state is always zero, but the terminal state is not the goal, it is the state which our agent transitions into once the episode has finished. We do backup by looking at the final timestep before our agent went into the terminal state - here it is easy to calculate the return. It is simply the reward that we received for moving into this state, because the expected return from the next state (terminal state) is always zero. Then using the recursive expression of returns (above), we can calculate the return for the timestep before that. This can be done recursively until we reach our initial state. At this point we know what all of the returns were for the whole episode.\n",
    "\n",
    "![](./images/backup.png)\n",
    "\n",
    "### So how good *is* each state?\n",
    "In general, the goal of reinforcement learning is to maximise the **expected** future reward. That is, to maximise the expected return from a the current state onwards. The measure of this, is called the *value* of the state (or the state value). A function that predicts this value is called a **state-value function** or **value function**.\n",
    "\n",
    "![](./images/value_def.png)\n",
    "\n",
    "If we had a way to estimate this, then we could look ahead to the state that each action would take us to and take the action which results in us landing in the state with best value. \n",
    "\n",
    "![](./images/follow_values.png)\n",
    "\n",
    "Values will not be updated for states that aren't visited to during an episode.\n",
    "\n",
    "If we initialise the value for each state as zero, and then average the return for each state over many episodes, that average return will converge to the true value of the state for this policy. This process of iteratively updating the value function is called **value iteration**.\n",
    "\n",
    "![](./images/update_values.png)\n",
    "\n",
    "Value iteration is a type of **value based** method. Notice that to learn an optimal policy, we never have to represent it explicitly. There is no function which represents the policy. Instead we just look-ahead and choose the action that maximises the value of the next state.\n",
    "\n",
    "Now that our agent is exploring the environment, let's implement value iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1\n",
    "i_episode=0\n",
    "discount_factor=0.8\n",
    "value_table = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Gs(episode_mem, discount_factor=0.95):\n",
    "    return episode_mem\n",
    "\n",
    "def update_value_table(value_table, episode_mem, alpha=0.5):\n",
    "    return value_table, v_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(policy, n_episodes=100):\n",
    "    global epsilon\n",
    "    global value_table\n",
    "    global i_episode\n",
    "    try:\n",
    "        for _ in range(n_episodes):\n",
    "            observation = env.reset()\n",
    "            episode_mem = []\n",
    "            done=False\n",
    "            t=0\n",
    "            while not done:\n",
    "                env.render()\n",
    "                time.sleep(0.05)\n",
    "                action = policy(observation)\n",
    "                new_observation, reward, done, info = env.step(action)\n",
    "                episode_mem.append({'observation':observation,\n",
    "                                    'action':action,\n",
    "                                    'reward':reward,\n",
    "                                    'new_observation':new_observation,\n",
    "                                    'done':done})\n",
    "                observation=new_observation\n",
    "                t+=1\n",
    "                epsilon*=0.999\n",
    "            episode_mem = calculate_Gs(episode_mem, discount_factor)\n",
    "            value_table, v_delta = update_value_table(value_table, episode_mem)\n",
    "            i_episode+=1\n",
    "            print(\"Episode {} finished after {} timesteps. Eplislon={}. V_Delta={}\".format(i_episode, t, epsilon, v_delta))\n",
    "            env.render()\n",
    "            time.sleep(1)\n",
    "        env.close()\n",
    "    except KeyboardInterrupt:\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(random_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we use the values that we know to perform well?\n",
    "\n",
    "Now that our agent is capable of exploring and learning about it's environment, we need to make it take advantage of what it knows so that it can perform well.\n",
    "Our random policy has helped us to estimate the values of each state, which means we have some idea of how good each state is. Think about how we could use this knowledge to make our agent perform well before reading the next paragraphs.\n",
    "\n",
    "In this simple version of the game, we know exactly what actions will lead us to what states. That means we have a perfect **model** of the environment. A model is a function that tells us how the state will change when we take certain actions. E.g. we know that if the agent tries to move up into an empty space, then that's where it will end up.\n",
    "\n",
    "Because we know exactly what states we can end up in by taking an action, we can just look at the value of the states and choose the action which leads us to the state with the greatest value. So we just move into the best state that we can reach at any point.\n",
    "A policy that always takes the action that it expects to end up in the best, currently reachable state is called a **greedy policy**.\n",
    "\n",
    "Let's implement a greedy policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transition model\n",
    "def transition(state, action):\n",
    "    state = np.copy(state)\n",
    "    agent_pos = list(zip(*np.where(state[2] == 1)))[0]\n",
    "    new_agent_pos = np.array(agent_pos)\n",
    "    if action==0:\n",
    "        new_agent_pos[1]-=1\n",
    "    elif action==1:\n",
    "        new_agent_pos[1]+=1\n",
    "    elif action==2:\n",
    "        new_agent_pos[0]-=1\n",
    "    elif action==3:\n",
    "        new_agent_pos[0]+=1    \n",
    "    new_agent_pos = np.clip(new_agent_pos, 0, 3)\n",
    "\n",
    "    state[2, agent_pos[0], agent_pos[1]] = 0 #moved from this position so it is empty\n",
    "    \n",
    "    state[2, new_agent_pos[0], new_agent_pos[1]] = 1 #moved to this position\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### implement greedy policy\n",
    "#greedy policy\n",
    "def greedy_policy(state):\n",
    "    return policy_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why not just act greedily all the time?\n",
    "\n",
    "If we act greedily all the time then we will move into the state with the best value. But remember that these values are only estimates based on our agent's experience with the game, which means that they might not be correct. So if we want to make sure that our agent will do well by always choosing the next action greedily, we need to make sure that it has good estimates for the values of those states. This brings us to a core challenge in reinforcement learning: **the exploration vs exploitation dilemma**. Our agent can either exploit what it knows by using it's current knowledge to choose the best action, or it can explore more and improve it's knowledge perhaps learning that some actions are even worse than what it does currently.\n",
    "\n",
    "## An epsilon-greedy policy\n",
    "We can combine our random policy and our greedy policy to make an improved policy that both explores its environment and exploits its current knowledge. An $\\epsilon$-greedy (epsilon-greedy) policy is one which exploits what it knows most of the time, but with probability $\\epsilon$ will instead select a random action to try.\n",
    "\n",
    "## Do we need to keep exploring once we are confident in the values of states?\n",
    "\n",
    "As our agent explores more, it becomes more confident in predicting how valuable any state is. Once it knows a lot, it should start to explore less and exploit what it knows more. That means that we should decrease epsilon over time.\n",
    "\n",
    "Let's implement it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state):\n",
    "    epsilon = 0.05\n",
    "    if random.random() < epsilon:\n",
    "        return random_policy(state)\n",
    "    else:\n",
    "        return greedy_policy(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we find an optimal policy?\n",
    "\n",
    "An optimal policy would take the best possible action in any state. Because of this, the optimal value function would give the maximum possible values for any state.\n",
    "\n",
    "In the first line below, the maximum state-value of a state is equivalent to the maximum state-action value when taking the best action in that state. Following this, we can derive a recursive definition of the optimal value function.\n",
    "\n",
    "In the last step, we even remove the policy from the equation entirely! This means that value iteration never needs to explicitly represent a policy in terms of a function that takes in a state and returns a distribution over actions.\n",
    "Instead, value iteration uses a **model**, $p(s', r | s, a)$, to look one step ahead, and take the action, $a$, that most likely leads it to the next state that has the best state-value function.\n",
    "\n",
    "A **model** defines how the state changes. It is also known as the transition dynamics of the environment. In our case the model is really simple: we are certain that taking the action to move right will move our agent one space to the right as long as there are no obstacles. There is no randomness in our environment (e.g. no wind that might push us into a different cell when we try to move right). That is, our environment is deterministic, not stochastic.\n",
    "\n",
    "![](./images/bellman_op_v.png)\n",
    "\n",
    "![](./images/backup_v.png)\n",
    "\n",
    "![](./images/update_rule_v.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement value iteration to find optimal value function\n",
    "def update_value_table(episode_mem, value_table, discount_factor=0.95, alpha=0.5):\n",
    "    return value_table, v_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Code solution with visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gym\n",
    "from GriddyEnv import GriddyEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(np.prod(env.observation_space.shape), 32)\n",
    "        self.fc2 = torch.nn.Linear(32, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, env.action_space.n)\n",
    "    def forward(self, obs):\n",
    "        obs = obs.view(-1, np.prod(env.observation_space.shape))\n",
    "        x = F.relu(self.fc1(obs))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def create_optimizer(self, lr=0.001):\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy(state):\n",
    "    return env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_greedy_policy(q_network):\n",
    "    def greedy_policy(state, return_action_val=False):\n",
    "        action_values = q_network(torch.tensor(state).double()).detach().numpy()\n",
    "        policy_action = np.argmax(action_values)\n",
    "        if return_action_val: return policy_action, action_values[0][policy_action]\n",
    "        return policy_action\n",
    "    return greedy_policy\n",
    "\n",
    "def create_stochastic_policy(q_network):\n",
    "    def stochastic_policy(state, return_action_val=False):\n",
    "        action_values = q_network(torch.tensor(state).double()).detach().numpy()\n",
    "        action_probs = F.softmax(torch.tensor(action_values), dim=-1)\n",
    "        policy_action = torch.distributions.Categorical(action_probs).sample().item()\n",
    "        if return_action_val: return policy_action, action_values[0][policy_action]\n",
    "        return policy_action\n",
    "    return stochastic_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epsilon_greedy_policy(policy):\n",
    "    def epsilon_greedy_policy(state):\n",
    "        action = env.action_space.sample() if np.random.rand()<epsilon else policy(state)\n",
    "        return action\n",
    "    return epsilon_greedy_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q\n",
    "def update_q_table(q_table, episode_mem, alpha=0.5):\n",
    "    all_diffs=[]\n",
    "    for mem in episode_mem:\n",
    "        key = pickle.dumps(np.array((*mem['observation'].flatten(), mem['action'])))\n",
    "        if key not in q_table:\n",
    "            q_table[key]=0 #initialize\n",
    "        new_val = q_table[key] + alpha*(mem['q']-q_table[key])\n",
    "        diff = abs(q_table[key]-new_val)\n",
    "        all_diffs.append(diff)\n",
    "        q_table[key] = new_val\n",
    "    return q_table, np.mean(all_diffs)\n",
    "\n",
    "def calculate_qs(episode_mem, discount_factor=0.95):\n",
    "    for i, mem in reversed(list(enumerate(episode_mem))):\n",
    "        if i==len(episode_mem)-1:\n",
    "            episode_mem[i]['q']= mem['reward']\n",
    "        else:\n",
    "            _, next_obs_q = greedy_policy(mem['new_observation'], return_action_val=True)\n",
    "            calculated_q = mem['reward']+discount_factor*next_obs_q\n",
    "            episode_mem[i]['q'] = calculated_q\n",
    "    return episode_mem\n",
    "\n",
    "def update_q_table(episode_mem, q_network, discount_factor=0.95, alpha=0.1):\n",
    "    all_diffs=[]\n",
    "    for i, mem in reversed(list(enumerate(episode_mem))):\n",
    "        if i==len(episode_mem)-1:\n",
    "            #episode_mem[i]['q']= mem['reward']\n",
    "            calculated_new_q= mem['reward']\n",
    "        else:\n",
    "            _, next_obs_q = greedy_policy(mem['new_observation'], return_action_val=True)\n",
    "            calculated_new_q = mem['reward']+discount_factor*next_obs_q\n",
    "            #episode_mem[i]['q'] = calculated_q\n",
    "        predicted_old_q = q_network(torch.tensor(mem['observation']).double())[0, mem['action']]\n",
    "        all_diffs.append(abs(calculated_new_q-predicted_old_q.item()))\n",
    "        label_new_q = predicted_old_q.item() + alpha*(calculated_new_q-predicted_old_q.item())\n",
    "        cost = F.mse_loss(predicted_old_q, torch.tensor(label_new_q).double())\n",
    "        cost.backward()\n",
    "        q_network.optimizer.step()\n",
    "        q_network.optimizer.zero_grad()   \n",
    "    return np.mean(all_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_table_viz(q_network):\n",
    "    qs = np.zeros((4, 4, 4))\n",
    "    base_st = np.zeros((3, 4, 4), dtype=np.int64)\n",
    "    base_st[0, 3, 3]=1\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            test_st = np.copy(base_st)\n",
    "            test_st[2, i, j] = 1\n",
    "            action_vals = q_network(torch.tensor(test_st).double())\n",
    "            for action in range(4):                \n",
    "                qs[action, i, j] = action_vals[0, action].item()\n",
    "    return qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_agent(policy, value_network=None, n=5):\n",
    "    try:\n",
    "        for trial_i in range(n):\n",
    "            observation = env.reset()\n",
    "            done=False\n",
    "            t=0\n",
    "            while not done:\n",
    "                if value_network: env.render(value_table_viz(value_network, observation))\n",
    "                else: env.render()\n",
    "                policy_action = policy(observation)\n",
    "                observation, reward, done, info = env.step(policy_action)\n",
    "                #time.sleep(0.5)\n",
    "                t+=1\n",
    "            env.render()\n",
    "            time.sleep(1.5)\n",
    "            print(\"Episode {} finished after {} timesteps\".format(trial_i, t))\n",
    "        env.close()\n",
    "    except KeyboardInterrupt:\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPER-PARAMS\n",
    "epsilon = 1\n",
    "i_episode=0\n",
    "discount_factor=0.95\n",
    "alpha=0.1\n",
    "lr = 0.001\n",
    "\n",
    "env = GriddyEnv(4, 4)\n",
    "#env = gym.make('CartPole-v1')\n",
    "q_network = QNetwork().double()\n",
    "q_network.create_optimizer(lr)\n",
    "greedy_policy = create_greedy_policy(q_network)\n",
    "stochastic_policy = create_stochastic_policy(q_network)\n",
    "epsilon_greedy_policy = create_epsilon_greedy_policy(greedy_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(policy, n_episodes=100):\n",
    "    global epsilon\n",
    "    global q_network\n",
    "    global i_episode\n",
    "    try:\n",
    "        for _ in range(n_episodes):\n",
    "            observation = env.reset()\n",
    "            episode_mem = []\n",
    "            done=False\n",
    "            t=0\n",
    "            while not done:\n",
    "                action = policy(observation)\n",
    "                new_observation, reward, done, info = env.step(action)\n",
    "                episode_mem.append({'observation':observation,\n",
    "                                    'action':action,\n",
    "                                    'reward':reward,\n",
    "                                    'new_observation':new_observation,\n",
    "                                    'done':done})\n",
    "                observation=new_observation\n",
    "                t+=1\n",
    "            epsilon*=0.995\n",
    "            q_delta = update_q_table(episode_mem, q_network, discount_factor, alpha)\n",
    "            i_episode+=1\n",
    "            print(\"Episode {} finished after {} timesteps. Eplislon={}. Q_Delta={}\".format(i_episode, t, epsilon, q_delta))#, end='\\r')\n",
    "            #print(value_table_viz(value_table))\n",
    "            #print()\n",
    "            #env.render(value_table_viz(value_network, observation))\n",
    "        env.close()\n",
    "    except KeyboardInterrupt:\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished after 51 timesteps. Eplislon=0.995. Q_Delta=0.04986628715166174\n",
      "Episode 2 finished after 23 timesteps. Eplislon=0.990025. Q_Delta=0.056947377301697\n",
      "Episode 3 finished after 86 timesteps. Eplislon=0.985074875. Q_Delta=0.021745694623375847\n",
      "Episode 4 finished after 20 timesteps. Eplislon=0.9801495006250001. Q_Delta=0.055985401194907844\n",
      "Episode 5 finished after 114 timesteps. Eplislon=0.9752487531218751. Q_Delta=0.02882166354646702\n",
      "Episode 6 finished after 45 timesteps. Eplislon=0.9703725093562657. Q_Delta=0.041306373344464804\n",
      "Episode 7 finished after 6 timesteps. Eplislon=0.9655206468094844. Q_Delta=0.1187547271733982\n",
      "Episode 8 finished after 15 timesteps. Eplislon=0.960693043575437. Q_Delta=0.06616494181511673\n",
      "Episode 9 finished after 35 timesteps. Eplislon=0.9558895783575597. Q_Delta=0.03837591349893982\n",
      "Episode 10 finished after 91 timesteps. Eplislon=0.9511101304657719. Q_Delta=0.0265574246309001\n",
      "Episode 11 finished after 40 timesteps. Eplislon=0.946354579813443. Q_Delta=0.030402817691144345\n",
      "Episode 12 finished after 69 timesteps. Eplislon=0.9416228069143757. Q_Delta=0.034585545621884456\n",
      "Episode 13 finished after 33 timesteps. Eplislon=0.9369146928798039. Q_Delta=0.034957663813066295\n",
      "Episode 14 finished after 20 timesteps. Eplislon=0.9322301194154049. Q_Delta=0.04128508963971593\n",
      "Episode 15 finished after 53 timesteps. Eplislon=0.9275689688183278. Q_Delta=0.031677247102740745\n",
      "Episode 16 finished after 54 timesteps. Eplislon=0.9229311239742362. Q_Delta=0.04727900981309304\n",
      "Episode 17 finished after 9 timesteps. Eplislon=0.918316468354365. Q_Delta=0.05667054498781031\n",
      "Episode 18 finished after 8 timesteps. Eplislon=0.9137248860125932. Q_Delta=0.029623990308673936\n",
      "Episode 19 finished after 2 timesteps. Eplislon=0.9091562615825302. Q_Delta=0.008194585718261538\n",
      "Episode 20 finished after 11 timesteps. Eplislon=0.9046104802746175. Q_Delta=0.02202329198206118\n",
      "Episode 21 finished after 83 timesteps. Eplislon=0.9000874278732445. Q_Delta=0.016130202890539323\n",
      "Episode 22 finished after 72 timesteps. Eplislon=0.8955869907338783. Q_Delta=0.016295149965743733\n",
      "Episode 23 finished after 56 timesteps. Eplislon=0.8911090557802088. Q_Delta=0.023452850015108277\n",
      "Episode 24 finished after 46 timesteps. Eplislon=0.8866535105013078. Q_Delta=0.02843856603381861\n",
      "Episode 25 finished after 10 timesteps. Eplislon=0.8822202429488013. Q_Delta=0.02510609797496487\n",
      "Episode 26 finished after 11 timesteps. Eplislon=0.8778091417340573. Q_Delta=0.02121432886317379\n",
      "Episode 27 finished after 28 timesteps. Eplislon=0.8734200960253871. Q_Delta=0.03258920410029895\n",
      "Episode 28 finished after 26 timesteps. Eplislon=0.8690529955452602. Q_Delta=0.025037226669285616\n",
      "Episode 29 finished after 8 timesteps. Eplislon=0.8647077305675338. Q_Delta=0.031018247241732133\n",
      "Episode 30 finished after 28 timesteps. Eplislon=0.8603841919146962. Q_Delta=0.031237674565881952\n",
      "Episode 31 finished after 5 timesteps. Eplislon=0.8560822709551227. Q_Delta=0.048674782188992724\n",
      "Episode 32 finished after 16 timesteps. Eplislon=0.851801859600347. Q_Delta=0.03782646814459451\n",
      "Episode 33 finished after 59 timesteps. Eplislon=0.8475428503023453. Q_Delta=0.02326494601500987\n",
      "Episode 34 finished after 8 timesteps. Eplislon=0.8433051360508336. Q_Delta=0.0378235392784495\n",
      "Episode 35 finished after 10 timesteps. Eplislon=0.8390886103705794. Q_Delta=0.0461191175856599\n",
      "Episode 36 finished after 21 timesteps. Eplislon=0.8348931673187264. Q_Delta=0.03509614503750225\n",
      "Episode 37 finished after 1 timesteps. Eplislon=0.8307187014821328. Q_Delta=0.0003253516929071498\n",
      "Episode 38 finished after 13 timesteps. Eplislon=0.8265651079747222. Q_Delta=0.016596692307344455\n",
      "Episode 39 finished after 21 timesteps. Eplislon=0.8224322824348486. Q_Delta=0.0261128801384706\n",
      "Episode 40 finished after 4 timesteps. Eplislon=0.8183201210226743. Q_Delta=0.013241834833932514\n",
      "Episode 41 finished after 4 timesteps. Eplislon=0.8142285204175609. Q_Delta=0.04115820949978624\n",
      "Episode 42 finished after 5 timesteps. Eplislon=0.810157377815473. Q_Delta=0.023549069482230345\n",
      "Episode 43 finished after 8 timesteps. Eplislon=0.8061065909263957. Q_Delta=0.016442496731551945\n",
      "Episode 44 finished after 15 timesteps. Eplislon=0.8020760579717637. Q_Delta=0.013813996526462986\n",
      "Episode 45 finished after 8 timesteps. Eplislon=0.798065677681905. Q_Delta=0.015573582532910565\n",
      "Episode 46 finished after 3 timesteps. Eplislon=0.7940753492934954. Q_Delta=0.011593119682319242\n",
      "Episode 47 finished after 23 timesteps. Eplislon=0.7901049725470279. Q_Delta=0.012851744901265104\n",
      "Episode 48 finished after 8 timesteps. Eplislon=0.7861544476842928. Q_Delta=0.012842150533121474\n",
      "Episode 49 finished after 6 timesteps. Eplislon=0.7822236754458713. Q_Delta=0.012316956232542512\n",
      "Episode 50 finished after 15 timesteps. Eplislon=0.778312557068642. Q_Delta=0.008404904098257877\n",
      "Episode 51 finished after 22 timesteps. Eplislon=0.7744209942832988. Q_Delta=0.014418531110828615\n",
      "Episode 52 finished after 8 timesteps. Eplislon=0.7705488893118823. Q_Delta=0.012559696362402603\n",
      "Episode 53 finished after 49 timesteps. Eplislon=0.7666961448653229. Q_Delta=0.013515744990514578\n",
      "Episode 54 finished after 15 timesteps. Eplislon=0.7628626641409962. Q_Delta=0.020740350676048774\n",
      "Episode 55 finished after 11 timesteps. Eplislon=0.7590483508202912. Q_Delta=0.015466873830530864\n",
      "Episode 56 finished after 1 timesteps. Eplislon=0.7552531090661897. Q_Delta=0.010713666575905112\n",
      "Episode 57 finished after 32 timesteps. Eplislon=0.7514768435208588. Q_Delta=0.016759055058197105\n",
      "Episode 58 finished after 9 timesteps. Eplislon=0.7477194593032545. Q_Delta=0.035992624437648085\n",
      "Episode 59 finished after 7 timesteps. Eplislon=0.7439808620067382. Q_Delta=0.026238293691287433\n",
      "Episode 60 finished after 16 timesteps. Eplislon=0.7402609576967045. Q_Delta=0.025007628203035627\n",
      "Episode 61 finished after 4 timesteps. Eplislon=0.736559652908221. Q_Delta=0.0176626980053253\n",
      "Episode 62 finished after 8 timesteps. Eplislon=0.7328768546436799. Q_Delta=0.014827152297140739\n",
      "Episode 63 finished after 4 timesteps. Eplislon=0.7292124703704616. Q_Delta=0.012143562585536033\n",
      "Episode 64 finished after 18 timesteps. Eplislon=0.7255664080186093. Q_Delta=0.018461997993603232\n",
      "Episode 65 finished after 15 timesteps. Eplislon=0.7219385759785162. Q_Delta=0.01955971967595959\n",
      "Episode 66 finished after 11 timesteps. Eplislon=0.7183288830986236. Q_Delta=0.015721676265820307\n",
      "Episode 67 finished after 22 timesteps. Eplislon=0.7147372386831305. Q_Delta=0.020654697356637584\n",
      "Episode 68 finished after 4 timesteps. Eplislon=0.7111635524897149. Q_Delta=0.030849826332843056\n",
      "Episode 69 finished after 9 timesteps. Eplislon=0.7076077347272662. Q_Delta=0.02835542967767736\n",
      "Episode 70 finished after 50 timesteps. Eplislon=0.7040696960536299. Q_Delta=0.022815377720039297\n",
      "Episode 71 finished after 11 timesteps. Eplislon=0.7005493475733617. Q_Delta=0.02079081958130735\n",
      "Episode 72 finished after 1 timesteps. Eplislon=0.697046600835495. Q_Delta=0.08329370797777313\n",
      "Episode 73 finished after 31 timesteps. Eplislon=0.6935613678313175. Q_Delta=0.024121221482366763\n",
      "Episode 74 finished after 6 timesteps. Eplislon=0.6900935609921609. Q_Delta=0.01638549840460322\n",
      "Episode 75 finished after 2 timesteps. Eplislon=0.6866430931872001. Q_Delta=0.01412322471520483\n",
      "Episode 76 finished after 2 timesteps. Eplislon=0.6832098777212641. Q_Delta=0.0351957631389303\n",
      "Episode 77 finished after 6 timesteps. Eplislon=0.6797938283326578. Q_Delta=0.018051527110390802\n",
      "Episode 78 finished after 13 timesteps. Eplislon=0.6763948591909945. Q_Delta=0.011501335835000476\n",
      "Episode 79 finished after 32 timesteps. Eplislon=0.6730128848950395. Q_Delta=0.009528351386711143\n",
      "Episode 80 finished after 4 timesteps. Eplislon=0.6696478204705644. Q_Delta=0.01598631792618077\n",
      "Episode 81 finished after 18 timesteps. Eplislon=0.6662995813682115. Q_Delta=0.01627736460508862\n",
      "Episode 82 finished after 30 timesteps. Eplislon=0.6629680834613705. Q_Delta=0.015440040996674457\n",
      "Episode 83 finished after 29 timesteps. Eplislon=0.6596532430440636. Q_Delta=0.014186529536652847\n",
      "Episode 84 finished after 3 timesteps. Eplislon=0.6563549768288433. Q_Delta=0.010964400913419584\n",
      "Episode 85 finished after 18 timesteps. Eplislon=0.653073201944699. Q_Delta=0.009831450420404841\n",
      "Episode 86 finished after 7 timesteps. Eplislon=0.6498078359349755. Q_Delta=0.014106403752529457\n",
      "Episode 87 finished after 3 timesteps. Eplislon=0.6465587967553006. Q_Delta=0.02263087910613304\n",
      "Episode 88 finished after 2 timesteps. Eplislon=0.6433260027715241. Q_Delta=0.014322835177007387\n",
      "Episode 89 finished after 18 timesteps. Eplislon=0.6401093727576664. Q_Delta=0.020810096640011364\n",
      "Episode 90 finished after 7 timesteps. Eplislon=0.6369088258938781. Q_Delta=0.01220811427770474\n",
      "Episode 91 finished after 6 timesteps. Eplislon=0.6337242817644086. Q_Delta=0.019721947452367272\n",
      "Episode 92 finished after 5 timesteps. Eplislon=0.6305556603555866. Q_Delta=0.01852825817108663\n",
      "Episode 93 finished after 9 timesteps. Eplislon=0.6274028820538087. Q_Delta=0.017830977959151537\n",
      "Episode 94 finished after 11 timesteps. Eplislon=0.6242658676435396. Q_Delta=0.00891603184212577\n",
      "Episode 95 finished after 5 timesteps. Eplislon=0.6211445383053219. Q_Delta=0.006914131466065987\n",
      "Episode 96 finished after 11 timesteps. Eplislon=0.6180388156137953. Q_Delta=0.009148476126179134\n",
      "Episode 97 finished after 8 timesteps. Eplislon=0.6149486215357263. Q_Delta=0.011872285612286676\n",
      "Episode 98 finished after 10 timesteps. Eplislon=0.6118738784280476. Q_Delta=0.01457135918334478\n",
      "Episode 99 finished after 6 timesteps. Eplislon=0.6088145090359074. Q_Delta=0.007734289812735347\n",
      "Episode 100 finished after 1 timesteps. Eplislon=0.6057704364907278. Q_Delta=0.013296049164812862\n",
      "Episode 101 finished after 5 timesteps. Eplislon=0.6027415843082742. Q_Delta=0.015786903824350617\n",
      "Episode 102 finished after 3 timesteps. Eplislon=0.5997278763867329. Q_Delta=0.006976567865145407\n",
      "Episode 103 finished after 2 timesteps. Eplislon=0.5967292370047992. Q_Delta=0.012602895105917278\n",
      "Episode 104 finished after 7 timesteps. Eplislon=0.5937455908197752. Q_Delta=0.008860208505992498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 105 finished after 28 timesteps. Eplislon=0.5907768628656763. Q_Delta=0.020146360036629635\n",
      "Episode 106 finished after 3 timesteps. Eplislon=0.5878229785513479. Q_Delta=0.04894994638155359\n",
      "Episode 107 finished after 3 timesteps. Eplislon=0.5848838636585911. Q_Delta=0.031681350629919315\n",
      "Episode 108 finished after 11 timesteps. Eplislon=0.5819594443402982. Q_Delta=0.03570705571483095\n",
      "Episode 109 finished after 19 timesteps. Eplislon=0.5790496471185967. Q_Delta=0.012107811341320714\n",
      "Episode 110 finished after 5 timesteps. Eplislon=0.5761543988830038. Q_Delta=0.03926569400799429\n",
      "Episode 111 finished after 7 timesteps. Eplislon=0.5732736268885887. Q_Delta=0.03310783952735468\n",
      "Episode 112 finished after 5 timesteps. Eplislon=0.5704072587541458. Q_Delta=0.01497484501213\n",
      "Episode 113 finished after 5 timesteps. Eplislon=0.567555222460375. Q_Delta=0.005559804730397544\n",
      "Episode 114 finished after 5 timesteps. Eplislon=0.5647174463480732. Q_Delta=0.014339550230658315\n",
      "Episode 115 finished after 5 timesteps. Eplislon=0.5618938591163328. Q_Delta=0.007648583990762759\n",
      "Episode 116 finished after 3 timesteps. Eplislon=0.5590843898207511. Q_Delta=0.01580546785714206\n",
      "Episode 117 finished after 5 timesteps. Eplislon=0.5562889678716474. Q_Delta=0.009469353598880658\n",
      "Episode 118 finished after 5 timesteps. Eplislon=0.5535075230322891. Q_Delta=0.007290312609963068\n",
      "Episode 119 finished after 4 timesteps. Eplislon=0.5507399854171277. Q_Delta=0.0032177349865419036\n",
      "Episode 120 finished after 9 timesteps. Eplislon=0.547986285490042. Q_Delta=0.014753084806910892\n",
      "Episode 121 finished after 3 timesteps. Eplislon=0.5452463540625918. Q_Delta=0.011402228093213304\n",
      "Episode 122 finished after 8 timesteps. Eplislon=0.5425201222922789. Q_Delta=0.013655611087060052\n",
      "Episode 123 finished after 4 timesteps. Eplislon=0.5398075216808175. Q_Delta=0.014778979380103169\n",
      "Episode 124 finished after 2 timesteps. Eplislon=0.5371084840724134. Q_Delta=0.011129105571261733\n",
      "Episode 125 finished after 2 timesteps. Eplislon=0.5344229416520513. Q_Delta=0.003113935500055953\n",
      "Episode 126 finished after 12 timesteps. Eplislon=0.531750826943791. Q_Delta=0.013809068349910303\n",
      "Episode 127 finished after 4 timesteps. Eplislon=0.5290920728090721. Q_Delta=0.019104205726880735\n",
      "Episode 128 finished after 4 timesteps. Eplislon=0.5264466124450268. Q_Delta=0.012810738027539958\n",
      "Episode 129 finished after 12 timesteps. Eplislon=0.5238143793828016. Q_Delta=0.015762023606691756\n",
      "Episode 130 finished after 7 timesteps. Eplislon=0.5211953074858876. Q_Delta=0.009979925563325118\n",
      "Episode 131 finished after 13 timesteps. Eplislon=0.5185893309484582. Q_Delta=0.008234867884054843\n",
      "Episode 132 finished after 7 timesteps. Eplislon=0.5159963842937159. Q_Delta=0.011606883934954983\n",
      "Episode 133 finished after 4 timesteps. Eplislon=0.5134164023722473. Q_Delta=0.007649365157412796\n",
      "Episode 134 finished after 4 timesteps. Eplislon=0.510849320360386. Q_Delta=0.00840756629425446\n",
      "Episode 135 finished after 6 timesteps. Eplislon=0.5082950737585841. Q_Delta=0.009375212285835896\n",
      "Episode 136 finished after 7 timesteps. Eplislon=0.5057535983897912. Q_Delta=0.014873931482724232\n",
      "Episode 137 finished after 12 timesteps. Eplislon=0.5032248303978422. Q_Delta=0.013203918942122953\n",
      "Episode 138 finished after 5 timesteps. Eplislon=0.500708706245853. Q_Delta=0.011008041488618846\n",
      "Episode 139 finished after 21 timesteps. Eplislon=0.4982051627146237. Q_Delta=0.012077198664816777\n",
      "Episode 140 finished after 1 timesteps. Eplislon=0.49571413690105054. Q_Delta=0.038590669086583373\n",
      "Episode 141 finished after 6 timesteps. Eplislon=0.4932355662165453. Q_Delta=0.01807088859246921\n",
      "Episode 142 finished after 6 timesteps. Eplislon=0.4907693883854626. Q_Delta=0.014171129103163704\n",
      "Episode 143 finished after 2 timesteps. Eplislon=0.4883155414435353. Q_Delta=0.024256055395301013\n",
      "Episode 144 finished after 35 timesteps. Eplislon=0.4858739637363176. Q_Delta=0.017435356165212038\n",
      "Episode 145 finished after 12 timesteps. Eplislon=0.483444593917636. Q_Delta=0.02025317094720373\n",
      "Episode 146 finished after 10 timesteps. Eplislon=0.4810273709480478. Q_Delta=0.028655252166867297\n",
      "Episode 147 finished after 8 timesteps. Eplislon=0.47862223409330756. Q_Delta=0.026408860281368796\n",
      "Episode 148 finished after 4 timesteps. Eplislon=0.47622912292284103. Q_Delta=0.010592674938018298\n",
      "Episode 149 finished after 15 timesteps. Eplislon=0.4738479773082268. Q_Delta=0.015403227013716488\n",
      "Episode 150 finished after 16 timesteps. Eplislon=0.47147873742168567. Q_Delta=0.016404654611605854\n",
      "Episode 151 finished after 2 timesteps. Eplislon=0.46912134373457726. Q_Delta=0.00691710528908801\n",
      "Episode 152 finished after 11 timesteps. Eplislon=0.46677573701590436. Q_Delta=0.025222262443462092\n",
      "Episode 153 finished after 4 timesteps. Eplislon=0.46444185833082485. Q_Delta=0.011592847348134094\n",
      "Episode 154 finished after 15 timesteps. Eplislon=0.46211964903917074. Q_Delta=0.023434245033573622\n",
      "Episode 155 finished after 6 timesteps. Eplislon=0.4598090507939749. Q_Delta=0.021963678889800737\n",
      "Episode 156 finished after 4 timesteps. Eplislon=0.457510005540005. Q_Delta=0.012226849913844234\n",
      "Episode 157 finished after 1 timesteps. Eplislon=0.45522245551230495. Q_Delta=0.017920432596098657\n",
      "Episode 158 finished after 6 timesteps. Eplislon=0.4529463432347434. Q_Delta=0.01675460998872937\n",
      "Episode 159 finished after 8 timesteps. Eplislon=0.4506816115185697. Q_Delta=0.029766483160217058\n",
      "Episode 160 finished after 91 timesteps. Eplislon=0.4484282034609769. Q_Delta=0.023043492168262403\n",
      "Episode 161 finished after 3 timesteps. Eplislon=0.446186062443672. Q_Delta=0.04979610353384567\n",
      "Episode 162 finished after 2 timesteps. Eplislon=0.4439551321314536. Q_Delta=0.03957783267875892\n",
      "Episode 163 finished after 4 timesteps. Eplislon=0.4417353564707963. Q_Delta=0.022736776225362243\n",
      "Episode 164 finished after 8 timesteps. Eplislon=0.43952667968844233. Q_Delta=0.021882246931271776\n",
      "Episode 165 finished after 16 timesteps. Eplislon=0.43732904629000013. Q_Delta=0.013590799060941731\n",
      "Episode 166 finished after 11 timesteps. Eplislon=0.4351424010585501. Q_Delta=0.03223462132862642\n",
      "Episode 167 finished after 13 timesteps. Eplislon=0.43296668905325736. Q_Delta=0.023419589748751555\n",
      "Episode 168 finished after 8 timesteps. Eplislon=0.43080185560799106. Q_Delta=0.022161995998233874\n",
      "Episode 169 finished after 3 timesteps. Eplislon=0.4286478463299511. Q_Delta=0.030779960306166216\n",
      "Episode 170 finished after 10 timesteps. Eplislon=0.42650460709830135. Q_Delta=0.022030778615619397\n",
      "Episode 171 finished after 7 timesteps. Eplislon=0.42437208406280985. Q_Delta=0.018625462688684875\n",
      "Episode 172 finished after 4 timesteps. Eplislon=0.4222502236424958. Q_Delta=0.013286623583055407\n",
      "Episode 173 finished after 7 timesteps. Eplislon=0.42013897252428334. Q_Delta=0.03588537375785591\n",
      "Episode 174 finished after 3 timesteps. Eplislon=0.4180382776616619. Q_Delta=0.02902299726089108\n",
      "Episode 175 finished after 2 timesteps. Eplislon=0.4159480862733536. Q_Delta=0.03041319388335545\n",
      "Episode 176 finished after 2 timesteps. Eplislon=0.41386834584198684. Q_Delta=0.02572140811432999\n",
      "Episode 177 finished after 10 timesteps. Eplislon=0.4117990041127769. Q_Delta=0.03144592017467549\n",
      "Episode 178 finished after 3 timesteps. Eplislon=0.40974000909221303. Q_Delta=0.026496648591820104\n",
      "Episode 179 finished after 5 timesteps. Eplislon=0.40769130904675194. Q_Delta=0.01945622616666698\n",
      "Episode 180 finished after 11 timesteps. Eplislon=0.40565285250151817. Q_Delta=0.019971095242046988\n",
      "Episode 181 finished after 2 timesteps. Eplislon=0.4036245882390106. Q_Delta=0.019977773174838065\n",
      "Episode 182 finished after 8 timesteps. Eplislon=0.4016064652978155. Q_Delta=0.01817935729368436\n",
      "Episode 183 finished after 5 timesteps. Eplislon=0.3995984329713264. Q_Delta=0.015845202597675502\n",
      "Episode 184 finished after 6 timesteps. Eplislon=0.3976004408064698. Q_Delta=0.009474025309172796\n",
      "Episode 185 finished after 3 timesteps. Eplislon=0.39561243860243744. Q_Delta=0.010476251393683059\n",
      "Episode 186 finished after 5 timesteps. Eplislon=0.3936343764094253. Q_Delta=0.023052914471662845\n",
      "Episode 187 finished after 7 timesteps. Eplislon=0.39166620452737816. Q_Delta=0.015890406634169803\n",
      "Episode 188 finished after 8 timesteps. Eplislon=0.3897078735047413. Q_Delta=0.007295561424499247\n",
      "Episode 189 finished after 1 timesteps. Eplislon=0.3877593341372176. Q_Delta=0.009829718213256844\n",
      "Episode 190 finished after 14 timesteps. Eplislon=0.3858205374665315. Q_Delta=0.008712219793310034\n",
      "Episode 191 finished after 4 timesteps. Eplislon=0.38389143477919885. Q_Delta=0.014554725291573312\n",
      "Episode 192 finished after 4 timesteps. Eplislon=0.3819719776053028. Q_Delta=0.006488846660154618\n",
      "Episode 193 finished after 4 timesteps. Eplislon=0.3800621177172763. Q_Delta=0.004797520024489521\n",
      "Episode 194 finished after 3 timesteps. Eplislon=0.37816180712868996. Q_Delta=0.005668372162390911\n",
      "Episode 195 finished after 5 timesteps. Eplislon=0.37627099809304654. Q_Delta=0.011510967973596608\n",
      "Episode 196 finished after 10 timesteps. Eplislon=0.3743896431025813. Q_Delta=0.01428164051921017\n",
      "Episode 197 finished after 2 timesteps. Eplislon=0.37251769488706843. Q_Delta=0.009591104908712067\n",
      "Episode 198 finished after 2 timesteps. Eplislon=0.3706551064126331. Q_Delta=0.008229353354633373\n",
      "Episode 199 finished after 2 timesteps. Eplislon=0.36880183088056995. Q_Delta=0.005474685708389659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200 finished after 15 timesteps. Eplislon=0.3669578217261671. Q_Delta=0.012575077396928366\n",
      "Episode 201 finished after 13 timesteps. Eplislon=0.36512303261753626. Q_Delta=0.015827056081499404\n",
      "Episode 202 finished after 3 timesteps. Eplislon=0.3632974174544486. Q_Delta=0.006650874675507956\n",
      "Episode 203 finished after 3 timesteps. Eplislon=0.3614809303671764. Q_Delta=0.004439213406411698\n",
      "Episode 204 finished after 3 timesteps. Eplislon=0.3596735257153405. Q_Delta=0.00535291236887514\n",
      "Episode 205 finished after 4 timesteps. Eplislon=0.3578751580867638. Q_Delta=0.010394307555756238\n",
      "Episode 206 finished after 6 timesteps. Eplislon=0.35608578229633. Q_Delta=0.01219462225119472\n",
      "Episode 207 finished after 2 timesteps. Eplislon=0.3543053533848483. Q_Delta=0.009607777554484387\n",
      "Episode 208 finished after 5 timesteps. Eplislon=0.35253382661792404. Q_Delta=0.012052036861087734\n",
      "Episode 209 finished after 6 timesteps. Eplislon=0.3507711574848344. Q_Delta=0.010305986701007944\n",
      "Episode 210 finished after 3 timesteps. Eplislon=0.34901730169741024. Q_Delta=0.009906218470891903\n",
      "Episode 211 finished after 1 timesteps. Eplislon=0.3472722151889232. Q_Delta=0.007956869571820402\n",
      "Episode 212 finished after 17 timesteps. Eplislon=0.3455358541129786. Q_Delta=0.009126169018401334\n",
      "Episode 213 finished after 2 timesteps. Eplislon=0.3438081748424137. Q_Delta=0.012555146111893234\n",
      "Episode 214 finished after 9 timesteps. Eplislon=0.3420891339682016. Q_Delta=0.01116065994741617\n",
      "Episode 215 finished after 2 timesteps. Eplislon=0.3403786882983606. Q_Delta=0.002604356423054899\n",
      "Episode 216 finished after 9 timesteps. Eplislon=0.3386767948568688. Q_Delta=0.007480536074339529\n",
      "Episode 217 finished after 3 timesteps. Eplislon=0.33698341088258443. Q_Delta=0.007780213699582779\n",
      "Episode 218 finished after 3 timesteps. Eplislon=0.3352984938281715. Q_Delta=0.0048386991712736265\n",
      "Episode 219 finished after 8 timesteps. Eplislon=0.33362200135903064. Q_Delta=0.004664902224069484\n",
      "Episode 220 finished after 11 timesteps. Eplislon=0.33195389135223546. Q_Delta=0.007204510261859612\n",
      "Episode 221 finished after 3 timesteps. Eplislon=0.3302941218954743. Q_Delta=0.00855664643706966\n",
      "Episode 222 finished after 4 timesteps. Eplislon=0.32864265128599696. Q_Delta=0.010465229959376099\n",
      "Episode 223 finished after 6 timesteps. Eplislon=0.326999438029567. Q_Delta=0.008241163232123982\n",
      "Episode 224 finished after 7 timesteps. Eplislon=0.3253644408394192. Q_Delta=0.005250501751223816\n",
      "Episode 225 finished after 3 timesteps. Eplislon=0.3237376186352221. Q_Delta=0.00031204598150539703\n",
      "Episode 226 finished after 5 timesteps. Eplislon=0.322118930542046. Q_Delta=0.003408052476859491\n",
      "Episode 227 finished after 3 timesteps. Eplislon=0.32050833588933575. Q_Delta=0.002735074549043204\n",
      "Episode 228 finished after 3 timesteps. Eplislon=0.31890579420988907. Q_Delta=0.004387542610676309\n",
      "Episode 229 finished after 3 timesteps. Eplislon=0.3173112652388396. Q_Delta=0.003518268627420699\n",
      "Episode 230 finished after 9 timesteps. Eplislon=0.3157247089126454. Q_Delta=0.007657755699393519\n",
      "Episode 231 finished after 10 timesteps. Eplislon=0.3141460853680822. Q_Delta=0.004727321337282875\n",
      "Episode 232 finished after 2 timesteps. Eplislon=0.3125753549412418. Q_Delta=0.006534289123519332\n",
      "Episode 233 finished after 2 timesteps. Eplislon=0.31101247816653554. Q_Delta=0.005365257906041199\n",
      "Episode 234 finished after 1 timesteps. Eplislon=0.30945741577570285. Q_Delta=0.00486587980969555\n",
      "Episode 235 finished after 4 timesteps. Eplislon=0.3079101286968243. Q_Delta=0.006083068794660501\n",
      "Episode 236 finished after 6 timesteps. Eplislon=0.3063705780533402. Q_Delta=0.004954660228891313\n",
      "Episode 237 finished after 2 timesteps. Eplislon=0.30483872516307353. Q_Delta=0.0046001457641851595\n",
      "Episode 238 finished after 8 timesteps. Eplislon=0.3033145315372582. Q_Delta=0.006278797266418529\n",
      "Episode 239 finished after 5 timesteps. Eplislon=0.3017979588795719. Q_Delta=0.0067526293546584125\n",
      "Episode 240 finished after 1 timesteps. Eplislon=0.30028896908517405. Q_Delta=0.01074637286584501\n",
      "Episode 241 finished after 3 timesteps. Eplislon=0.2987875242397482. Q_Delta=0.006518442811640786\n",
      "Episode 242 finished after 9 timesteps. Eplislon=0.29729358661854943. Q_Delta=0.01207241418034498\n",
      "Episode 243 finished after 2 timesteps. Eplislon=0.29580711868545667. Q_Delta=0.00862421877603009\n",
      "Episode 244 finished after 4 timesteps. Eplislon=0.2943280830920294. Q_Delta=0.009395766977145031\n",
      "Episode 245 finished after 4 timesteps. Eplislon=0.29285644267656924. Q_Delta=0.007520731178649681\n",
      "Episode 246 finished after 9 timesteps. Eplislon=0.2913921604631864. Q_Delta=0.0120296106267873\n",
      "Episode 247 finished after 3 timesteps. Eplislon=0.28993519966087045. Q_Delta=0.011597991080925518\n",
      "Episode 248 finished after 4 timesteps. Eplislon=0.2884855236625661. Q_Delta=0.004256619036715759\n",
      "Episode 249 finished after 5 timesteps. Eplislon=0.28704309604425327. Q_Delta=0.010697847399120785\n",
      "Episode 250 finished after 8 timesteps. Eplislon=0.285607880564032. Q_Delta=0.006814272651355827\n",
      "Episode 251 finished after 4 timesteps. Eplislon=0.28417984116121187. Q_Delta=0.008727993488075236\n",
      "Episode 252 finished after 3 timesteps. Eplislon=0.2827589419554058. Q_Delta=0.0059967468901472865\n",
      "Episode 253 finished after 5 timesteps. Eplislon=0.28134514724562876. Q_Delta=0.01077178623925168\n",
      "Episode 254 finished after 3 timesteps. Eplislon=0.2799384215094006. Q_Delta=0.0037895556405212285\n",
      "Episode 255 finished after 9 timesteps. Eplislon=0.27853872940185365. Q_Delta=0.018218760282023825\n",
      "Episode 256 finished after 2 timesteps. Eplislon=0.27714603575484437. Q_Delta=0.019837644339933735\n",
      "Episode 257 finished after 9 timesteps. Eplislon=0.2757603055760701. Q_Delta=0.008632428091202115\n",
      "Episode 258 finished after 6 timesteps. Eplislon=0.2743815040481898. Q_Delta=0.010948851151624084\n",
      "Episode 259 finished after 2 timesteps. Eplislon=0.2730095965279488. Q_Delta=0.006358515675632281\n",
      "Episode 260 finished after 4 timesteps. Eplislon=0.27164454854530906. Q_Delta=0.006365832307954483\n",
      "Episode 261 finished after 9 timesteps. Eplislon=0.2702863258025825. Q_Delta=0.012176674488177386\n",
      "Episode 262 finished after 8 timesteps. Eplislon=0.2689348941735696. Q_Delta=0.013016078415667307\n",
      "Episode 263 finished after 4 timesteps. Eplislon=0.26759021970270175. Q_Delta=0.010422305373191998\n",
      "Episode 264 finished after 4 timesteps. Eplislon=0.2662522686041882. Q_Delta=0.00714354528853009\n",
      "Episode 265 finished after 1 timesteps. Eplislon=0.2649210072611673. Q_Delta=0.017445728902553803\n",
      "Episode 266 finished after 3 timesteps. Eplislon=0.26359640222486147. Q_Delta=0.016195120535090757\n",
      "Episode 267 finished after 5 timesteps. Eplislon=0.26227842021373715. Q_Delta=0.012276457118958795\n",
      "Episode 268 finished after 5 timesteps. Eplislon=0.2609670281126685. Q_Delta=0.013602530179838635\n",
      "Episode 269 finished after 7 timesteps. Eplislon=0.25966219297210513. Q_Delta=0.005810646455077213\n",
      "Episode 270 finished after 6 timesteps. Eplislon=0.2583638820072446. Q_Delta=0.007610804894643941\n",
      "Episode 271 finished after 1 timesteps. Eplislon=0.2570720625972084. Q_Delta=0.009648433534594547\n",
      "Episode 272 finished after 3 timesteps. Eplislon=0.25578670228422234. Q_Delta=0.009644451861273532\n",
      "Episode 273 finished after 4 timesteps. Eplislon=0.25450776877280124. Q_Delta=0.0031997385489015984\n",
      "Episode 274 finished after 2 timesteps. Eplislon=0.2532352299289372. Q_Delta=0.009519529676302707\n",
      "Episode 275 finished after 4 timesteps. Eplislon=0.2519690537792925. Q_Delta=0.00882573839313483\n",
      "Episode 276 finished after 8 timesteps. Eplislon=0.2507092085103961. Q_Delta=0.009496913766409168\n",
      "Episode 277 finished after 1 timesteps. Eplislon=0.2494556624678441. Q_Delta=0.024010935359193963\n",
      "Episode 278 finished after 1 timesteps. Eplislon=0.24820838415550486. Q_Delta=0.02089646486156016\n",
      "Episode 279 finished after 1 timesteps. Eplislon=0.24696734223472733. Q_Delta=0.015223979466708837\n",
      "Episode 280 finished after 2 timesteps. Eplislon=0.2457325055235537. Q_Delta=0.009259354275046816\n",
      "Episode 281 finished after 6 timesteps. Eplislon=0.24450384299593592. Q_Delta=0.005566868458404335\n",
      "Episode 282 finished after 6 timesteps. Eplislon=0.24328132378095624. Q_Delta=0.006466657953271245\n",
      "Episode 283 finished after 2 timesteps. Eplislon=0.24206491716205145. Q_Delta=0.004931073217115223\n",
      "Episode 284 finished after 4 timesteps. Eplislon=0.2408545925762412. Q_Delta=0.004784490088233007\n",
      "Episode 285 finished after 8 timesteps. Eplislon=0.23965031961336. Q_Delta=0.004081774488967113\n",
      "Episode 286 finished after 6 timesteps. Eplislon=0.2384520680152932. Q_Delta=0.004519081197117747\n",
      "Episode 287 finished after 3 timesteps. Eplislon=0.23725980767521673. Q_Delta=0.008124246580103208\n",
      "Episode 288 finished after 3 timesteps. Eplislon=0.23607350863684065. Q_Delta=0.007249352114498582\n",
      "Episode 289 finished after 6 timesteps. Eplislon=0.23489314109365644. Q_Delta=0.008115728063689523\n",
      "Episode 290 finished after 4 timesteps. Eplislon=0.23371867538818816. Q_Delta=0.0028093961817738933\n",
      "Episode 291 finished after 2 timesteps. Eplislon=0.23255008201124722. Q_Delta=0.0010180585322211444\n",
      "Episode 292 finished after 1 timesteps. Eplislon=0.231387331601191. Q_Delta=0.0055013667045329395\n",
      "Episode 293 finished after 3 timesteps. Eplislon=0.23023039494318503. Q_Delta=0.0016718517932150512\n",
      "Episode 294 finished after 4 timesteps. Eplislon=0.2290792429684691. Q_Delta=0.0019579785761958957\n",
      "Episode 295 finished after 4 timesteps. Eplislon=0.22793384675362674. Q_Delta=0.0017110510159396852\n",
      "Episode 296 finished after 1 timesteps. Eplislon=0.22679417751985861. Q_Delta=0.00457520459996319\n",
      "Episode 297 finished after 8 timesteps. Eplislon=0.22566020663225933. Q_Delta=0.003828036434980475\n",
      "Episode 298 finished after 9 timesteps. Eplislon=0.22453190559909803. Q_Delta=0.00406605048435043\n",
      "Episode 299 finished after 2 timesteps. Eplislon=0.22340924607110255. Q_Delta=0.0019800091096799366\n",
      "Episode 300 finished after 1 timesteps. Eplislon=0.22229219984074702. Q_Delta=0.003958581582426235\n",
      "Episode 301 finished after 4 timesteps. Eplislon=0.2211807388415433. Q_Delta=0.007758892657695388\n",
      "Episode 302 finished after 4 timesteps. Eplislon=0.22007483514733558. Q_Delta=0.004880172491668416\n",
      "Episode 303 finished after 4 timesteps. Eplislon=0.2189744609715989. Q_Delta=0.0018683732277487708\n",
      "Episode 304 finished after 3 timesteps. Eplislon=0.2178795886667409. Q_Delta=0.004245654217738999\n",
      "Episode 305 finished after 9 timesteps. Eplislon=0.2167901907234072. Q_Delta=0.009475204791740847\n",
      "Episode 306 finished after 5 timesteps. Eplislon=0.21570623976979014. Q_Delta=0.005076063647372298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 307 finished after 6 timesteps. Eplislon=0.21462770857094118. Q_Delta=0.007905978554825721\n",
      "Episode 308 finished after 5 timesteps. Eplislon=0.21355457002808648. Q_Delta=0.008984661812290119\n",
      "Episode 309 finished after 3 timesteps. Eplislon=0.21248679717794605. Q_Delta=0.004933824127484221\n",
      "Episode 310 finished after 8 timesteps. Eplislon=0.21142436319205632. Q_Delta=0.004266256453677883\n",
      "Episode 311 finished after 7 timesteps. Eplislon=0.21036724137609603. Q_Delta=0.0045295896390898606\n",
      "Episode 312 finished after 4 timesteps. Eplislon=0.20931540516921554. Q_Delta=0.004891946655480289\n",
      "Episode 313 finished after 4 timesteps. Eplislon=0.20826882814336947. Q_Delta=0.010013760796200283\n",
      "Episode 314 finished after 7 timesteps. Eplislon=0.20722748400265262. Q_Delta=0.007631506822683479\n",
      "Episode 315 finished after 3 timesteps. Eplislon=0.20619134658263935. Q_Delta=0.007424825090603789\n",
      "Episode 316 finished after 5 timesteps. Eplislon=0.20516038984972615. Q_Delta=0.005921788933210737\n",
      "Episode 317 finished after 5 timesteps. Eplislon=0.2041345879004775. Q_Delta=0.0033178059447669162\n",
      "Episode 318 finished after 2 timesteps. Eplislon=0.2031139149609751. Q_Delta=0.0031749868740399423\n",
      "Episode 319 finished after 7 timesteps. Eplislon=0.20209834538617025. Q_Delta=0.005845829237571091\n",
      "Episode 320 finished after 9 timesteps. Eplislon=0.2010878536592394. Q_Delta=0.013903424361117257\n",
      "Episode 321 finished after 1 timesteps. Eplislon=0.2000824143909432. Q_Delta=0.005696156508014694\n",
      "Episode 322 finished after 11 timesteps. Eplislon=0.19908200231898848. Q_Delta=0.010060069632142999\n",
      "Episode 323 finished after 6 timesteps. Eplislon=0.19808659230739353. Q_Delta=0.0049037930374288274\n",
      "Episode 324 finished after 4 timesteps. Eplislon=0.19709615934585656. Q_Delta=0.006602794585288285\n",
      "Episode 325 finished after 1 timesteps. Eplislon=0.19611067854912728. Q_Delta=0.0022809330790078963\n",
      "Episode 326 finished after 3 timesteps. Eplislon=0.19513012515638165. Q_Delta=0.004610068848155846\n",
      "Episode 327 finished after 1 timesteps. Eplislon=0.19415447453059972. Q_Delta=0.004659526085329269\n",
      "Episode 328 finished after 1 timesteps. Eplislon=0.19318370215794672. Q_Delta=0.00873409691360072\n",
      "Episode 329 finished after 6 timesteps. Eplislon=0.192217783647157. Q_Delta=0.00834590206215787\n",
      "Episode 330 finished after 5 timesteps. Eplislon=0.1912566947289212. Q_Delta=0.012100941214925243\n",
      "Episode 331 finished after 3 timesteps. Eplislon=0.1903004112552766. Q_Delta=0.00830316386024014\n",
      "Episode 332 finished after 9 timesteps. Eplislon=0.18934890919900021. Q_Delta=0.01429473646024119\n",
      "Episode 333 finished after 3 timesteps. Eplislon=0.18840216465300522. Q_Delta=0.006824081712886361\n",
      "Episode 334 finished after 3 timesteps. Eplislon=0.18746015382974018. Q_Delta=0.00879345919367184\n",
      "Episode 335 finished after 3 timesteps. Eplislon=0.1865228530605915. Q_Delta=0.008298746716911479\n",
      "Episode 336 finished after 2 timesteps. Eplislon=0.18559023879528855. Q_Delta=0.0051698452559815755\n",
      "Episode 337 finished after 3 timesteps. Eplislon=0.1846622876013121. Q_Delta=0.009110202084797847\n",
      "Episode 338 finished after 7 timesteps. Eplislon=0.18373897616330553. Q_Delta=0.008818697293461806\n",
      "Episode 339 finished after 5 timesteps. Eplislon=0.182820281282489. Q_Delta=0.011211406813127423\n",
      "Episode 340 finished after 7 timesteps. Eplislon=0.18190617987607657. Q_Delta=0.01638232561815554\n",
      "Episode 341 finished after 1 timesteps. Eplislon=0.18099664897669618. Q_Delta=0.014044417467121373\n",
      "Episode 342 finished after 1 timesteps. Eplislon=0.1800916657318127. Q_Delta=0.0006137823303801193\n",
      "Episode 343 finished after 5 timesteps. Eplislon=0.17919120740315364. Q_Delta=0.013032318552880496\n",
      "Episode 344 finished after 6 timesteps. Eplislon=0.17829525136613786. Q_Delta=0.006627235812630805\n",
      "Episode 345 finished after 7 timesteps. Eplislon=0.17740377510930716. Q_Delta=0.010953051247304153\n",
      "Episode 346 finished after 1 timesteps. Eplislon=0.17651675623376062. Q_Delta=0.00014642822764332486\n",
      "Episode 347 finished after 2 timesteps. Eplislon=0.1756341724525918. Q_Delta=0.001040607794644599\n",
      "Episode 348 finished after 6 timesteps. Eplislon=0.17475600159032884. Q_Delta=0.018371298283848037\n",
      "Episode 349 finished after 5 timesteps. Eplislon=0.17388222158237718. Q_Delta=0.010559794366396914\n",
      "Episode 350 finished after 3 timesteps. Eplislon=0.1730128104744653. Q_Delta=0.01776751692684375\n",
      "Episode 351 finished after 2 timesteps. Eplislon=0.17214774642209296. Q_Delta=0.01446436954626601\n",
      "Episode 352 finished after 4 timesteps. Eplislon=0.1712870076899825. Q_Delta=0.010038931452939936\n",
      "Episode 353 finished after 7 timesteps. Eplislon=0.17043057265153258. Q_Delta=0.007250751816394262\n",
      "Episode 354 finished after 3 timesteps. Eplislon=0.16957841978827493. Q_Delta=0.021622052864455694\n",
      "Episode 355 finished after 6 timesteps. Eplislon=0.16873052768933355. Q_Delta=0.015256252128929707\n",
      "Episode 356 finished after 3 timesteps. Eplislon=0.1678868750508869. Q_Delta=0.006243798400009178\n",
      "Episode 357 finished after 3 timesteps. Eplislon=0.16704744067563246. Q_Delta=0.023582659118630594\n",
      "Episode 358 finished after 3 timesteps. Eplislon=0.1662122034722543. Q_Delta=0.0030559588052762785\n",
      "Episode 359 finished after 2 timesteps. Eplislon=0.16538114245489302. Q_Delta=0.01843764603358461\n",
      "Episode 360 finished after 4 timesteps. Eplislon=0.16455423674261854. Q_Delta=0.012416841481761837\n",
      "Episode 361 finished after 3 timesteps. Eplislon=0.16373146555890544. Q_Delta=0.006017259850382965\n",
      "Episode 362 finished after 4 timesteps. Eplislon=0.16291280823111093. Q_Delta=0.00494209750642885\n",
      "Episode 363 finished after 2 timesteps. Eplislon=0.16209824418995536. Q_Delta=0.004790958373439402\n",
      "Episode 364 finished after 1 timesteps. Eplislon=0.16128775296900558. Q_Delta=0.003986377857397194\n",
      "Episode 365 finished after 4 timesteps. Eplislon=0.16048131420416054. Q_Delta=0.005177261060299643\n",
      "Episode 366 finished after 6 timesteps. Eplislon=0.15967890763313974. Q_Delta=0.007662100756771206\n",
      "Episode 367 finished after 3 timesteps. Eplislon=0.15888051309497406. Q_Delta=0.010717396846835\n",
      "Episode 368 finished after 4 timesteps. Eplislon=0.1580861105294992. Q_Delta=0.007843617896804406\n",
      "Episode 369 finished after 3 timesteps. Eplislon=0.1572956799768517. Q_Delta=0.009383940639402177\n",
      "Episode 370 finished after 2 timesteps. Eplislon=0.15650920157696743. Q_Delta=0.01095474991304829\n",
      "Episode 371 finished after 7 timesteps. Eplislon=0.1557266555690826. Q_Delta=0.00915908840096499\n",
      "Episode 372 finished after 2 timesteps. Eplislon=0.1549480222912372. Q_Delta=0.009900458509756072\n",
      "Episode 373 finished after 1 timesteps. Eplislon=0.15417328217978102. Q_Delta=0.014510979184734873\n",
      "Episode 374 finished after 3 timesteps. Eplislon=0.1534024157688821. Q_Delta=0.009371252732809069\n",
      "Episode 375 finished after 4 timesteps. Eplislon=0.1526354036900377. Q_Delta=0.00994463468021145\n",
      "Episode 376 finished after 7 timesteps. Eplislon=0.1518722266715875. Q_Delta=0.0066082183387601145\n",
      "Episode 377 finished after 5 timesteps. Eplislon=0.15111286553822956. Q_Delta=0.0062924117675491106\n",
      "Episode 378 finished after 3 timesteps. Eplislon=0.15035730121053842. Q_Delta=0.008268995472351789\n",
      "Episode 379 finished after 2 timesteps. Eplislon=0.14960551470448571. Q_Delta=0.005609766561765928\n",
      "Episode 380 finished after 6 timesteps. Eplislon=0.14885748713096328. Q_Delta=0.00670495265273154\n",
      "Episode 381 finished after 4 timesteps. Eplislon=0.14811319969530845. Q_Delta=0.0150406133198549\n",
      "Episode 382 finished after 3 timesteps. Eplislon=0.1473726336968319. Q_Delta=0.008598857772192011\n",
      "Episode 383 finished after 8 timesteps. Eplislon=0.14663577052834775. Q_Delta=0.010198495326735557\n",
      "Episode 384 finished after 3 timesteps. Eplislon=0.14590259167570602. Q_Delta=0.018951722357896734\n",
      "Episode 385 finished after 2 timesteps. Eplislon=0.1451730787173275. Q_Delta=0.015870382535762062\n",
      "Episode 386 finished after 3 timesteps. Eplislon=0.14444721332374086. Q_Delta=0.01678262721677552\n",
      "Episode 387 finished after 7 timesteps. Eplislon=0.14372497725712216. Q_Delta=0.018528525950479872\n",
      "Episode 388 finished after 1 timesteps. Eplislon=0.14300635237083656. Q_Delta=0.010827634858139756\n",
      "Episode 389 finished after 3 timesteps. Eplislon=0.14229132060898236. Q_Delta=0.007084153380604234\n",
      "Episode 390 finished after 3 timesteps. Eplislon=0.14157986400593744. Q_Delta=0.010492056571475486\n",
      "Episode 391 finished after 3 timesteps. Eplislon=0.14087196468590776. Q_Delta=0.00897091552827615\n",
      "Episode 392 finished after 6 timesteps. Eplislon=0.14016760486247823. Q_Delta=0.01445788101952176\n",
      "Episode 393 finished after 5 timesteps. Eplislon=0.13946676683816583. Q_Delta=0.009218659949449459\n",
      "Episode 394 finished after 3 timesteps. Eplislon=0.138769433003975. Q_Delta=0.005517811624644005\n",
      "Episode 395 finished after 5 timesteps. Eplislon=0.13807558583895513. Q_Delta=0.00759091783762027\n",
      "Episode 396 finished after 3 timesteps. Eplislon=0.13738520790976036. Q_Delta=0.005785385614019978\n",
      "Episode 397 finished after 4 timesteps. Eplislon=0.13669828187021155. Q_Delta=0.007202291983972237\n",
      "Episode 398 finished after 2 timesteps. Eplislon=0.13601479046086049. Q_Delta=0.0014173923848589398\n",
      "Episode 399 finished after 5 timesteps. Eplislon=0.1353347165085562. Q_Delta=0.004880127991149186\n",
      "Episode 400 finished after 4 timesteps. Eplislon=0.1346580429260134. Q_Delta=0.0073789849049282485\n",
      "Episode 401 finished after 3 timesteps. Eplislon=0.13398475271138335. Q_Delta=0.009563295587699564\n",
      "Episode 402 finished after 1 timesteps. Eplislon=0.13331482894782642. Q_Delta=0.012902870371467534\n",
      "Episode 403 finished after 2 timesteps. Eplislon=0.13264825480308728. Q_Delta=0.010843101004660183\n",
      "Episode 404 finished after 2 timesteps. Eplislon=0.13198501352907185. Q_Delta=0.011021591214855186\n",
      "Episode 405 finished after 2 timesteps. Eplislon=0.1313250884614265. Q_Delta=0.006721658717742773\n",
      "Episode 406 finished after 8 timesteps. Eplislon=0.13066846301911936. Q_Delta=0.009251638862633069\n",
      "Episode 407 finished after 7 timesteps. Eplislon=0.13001512070402377. Q_Delta=0.012514318982519868\n",
      "Episode 408 finished after 5 timesteps. Eplislon=0.12936504510050365. Q_Delta=0.013235026900938186\n",
      "Episode 409 finished after 5 timesteps. Eplislon=0.12871821987500112. Q_Delta=0.009932957001019371\n",
      "Episode 410 finished after 4 timesteps. Eplislon=0.12807462877562611. Q_Delta=0.012909414953713116\n",
      "Episode 411 finished after 3 timesteps. Eplislon=0.12743425563174798. Q_Delta=0.01423711469088377\n",
      "Episode 412 finished after 5 timesteps. Eplislon=0.12679708435358925. Q_Delta=0.01280242196143977\n",
      "Episode 413 finished after 4 timesteps. Eplislon=0.1261630989318213. Q_Delta=0.00798326059567292\n",
      "Episode 414 finished after 3 timesteps. Eplislon=0.1255322834371622. Q_Delta=0.011157079127796843\n",
      "Episode 415 finished after 2 timesteps. Eplislon=0.12490462201997637. Q_Delta=0.011265062870743192\n",
      "Episode 416 finished after 4 timesteps. Eplislon=0.1242800989098765. Q_Delta=0.007538485370753495\n",
      "Episode 417 finished after 2 timesteps. Eplislon=0.12365869841532712. Q_Delta=0.020494913040707774\n",
      "Episode 418 finished after 3 timesteps. Eplislon=0.12304040492325048. Q_Delta=0.006407614266515112\n",
      "Episode 419 finished after 3 timesteps. Eplislon=0.12242520289863423. Q_Delta=0.008033641202567962\n",
      "Episode 420 finished after 6 timesteps. Eplislon=0.12181307688414106. Q_Delta=0.01730147764108675\n",
      "Episode 421 finished after 4 timesteps. Eplislon=0.12120401149972035. Q_Delta=0.0066598439781584695\n",
      "Episode 422 finished after 1 timesteps. Eplislon=0.12059799144222175. Q_Delta=0.009120193773735075\n",
      "Episode 423 finished after 3 timesteps. Eplislon=0.11999500148501063. Q_Delta=0.00732987231838859\n",
      "Episode 424 finished after 4 timesteps. Eplislon=0.11939502647758558. Q_Delta=0.005492592102056104\n",
      "Episode 425 finished after 5 timesteps. Eplislon=0.11879805134519765. Q_Delta=0.005561742650225176\n",
      "Episode 426 finished after 2 timesteps. Eplislon=0.11820406108847166. Q_Delta=0.011084468798655434\n",
      "Episode 427 finished after 3 timesteps. Eplislon=0.1176130407830293. Q_Delta=0.005079276535951564\n",
      "Episode 428 finished after 1 timesteps. Eplislon=0.11702497557911415. Q_Delta=0.003994656809601871\n",
      "Episode 429 finished after 5 timesteps. Eplislon=0.11643985070121858. Q_Delta=0.0037072403777390186\n",
      "Episode 430 finished after 3 timesteps. Eplislon=0.11585765144771248. Q_Delta=0.00446942027550401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 431 finished after 3 timesteps. Eplislon=0.11527836319047392. Q_Delta=0.003200969466322201\n",
      "Episode 432 finished after 5 timesteps. Eplislon=0.11470197137452155. Q_Delta=0.006236093516882457\n",
      "Episode 433 finished after 5 timesteps. Eplislon=0.11412846151764894. Q_Delta=0.013108714909293084\n",
      "Episode 434 finished after 1 timesteps. Eplislon=0.1135578192100607. Q_Delta=0.012357474611901065\n",
      "Episode 435 finished after 1 timesteps. Eplislon=0.11299003011401039. Q_Delta=0.00508299209440799\n",
      "Episode 436 finished after 2 timesteps. Eplislon=0.11242507996344034. Q_Delta=0.006660552900823846\n",
      "Episode 437 finished after 3 timesteps. Eplislon=0.11186295456362313. Q_Delta=0.0039487370428384905\n",
      "Episode 438 finished after 3 timesteps. Eplislon=0.11130363979080501. Q_Delta=0.0022965453444757644\n",
      "Episode 439 finished after 3 timesteps. Eplislon=0.11074712159185099. Q_Delta=0.01628315133202385\n",
      "Episode 440 finished after 4 timesteps. Eplislon=0.11019338598389174. Q_Delta=0.005263421534251023\n",
      "Episode 441 finished after 2 timesteps. Eplislon=0.10964241905397228. Q_Delta=0.014498097146954936\n",
      "Episode 442 finished after 3 timesteps. Eplislon=0.10909420695870241. Q_Delta=0.009687142830999177\n",
      "Episode 443 finished after 3 timesteps. Eplislon=0.1085487359239089. Q_Delta=0.006933510010530812\n",
      "Episode 444 finished after 4 timesteps. Eplislon=0.10800599224428936. Q_Delta=0.007106454398349948\n",
      "Episode 445 finished after 6 timesteps. Eplislon=0.10746596228306791. Q_Delta=0.007263751890174974\n",
      "Episode 446 finished after 6 timesteps. Eplislon=0.10692863247165257. Q_Delta=0.008500125540243061\n",
      "Episode 447 finished after 1 timesteps. Eplislon=0.1063939893092943. Q_Delta=0.020325413189711705\n",
      "Episode 448 finished after 4 timesteps. Eplislon=0.10586201936274783. Q_Delta=0.009551073782079395\n",
      "Episode 449 finished after 1 timesteps. Eplislon=0.10533270926593409. Q_Delta=0.0036348478577412635\n",
      "Episode 450 finished after 2 timesteps. Eplislon=0.10480604571960442. Q_Delta=0.009912107099242451\n",
      "Episode 451 finished after 1 timesteps. Eplislon=0.1042820154910064. Q_Delta=0.01033643362873038\n",
      "Episode 452 finished after 4 timesteps. Eplislon=0.10376060541355137. Q_Delta=0.007750773849837939\n",
      "Episode 453 finished after 3 timesteps. Eplislon=0.1032418023864836. Q_Delta=0.0020607763940657295\n",
      "Episode 454 finished after 2 timesteps. Eplislon=0.10272559337455119. Q_Delta=0.005265787805373678\n",
      "Episode 455 finished after 4 timesteps. Eplislon=0.10221196540767843. Q_Delta=0.0037544214723062297\n",
      "Episode 456 finished after 3 timesteps. Eplislon=0.10170090558064004. Q_Delta=0.003723444193654557\n",
      "Episode 457 finished after 1 timesteps. Eplislon=0.10119240105273684. Q_Delta=0.00038310963980947577\n",
      "Episode 458 finished after 5 timesteps. Eplislon=0.10068643904747315. Q_Delta=0.0007342686576319535\n",
      "Episode 459 finished after 5 timesteps. Eplislon=0.10018300685223579. Q_Delta=0.0010956842987939863\n",
      "Episode 460 finished after 1 timesteps. Eplislon=0.0996820918179746. Q_Delta=0.004593495267373626\n",
      "Episode 461 finished after 5 timesteps. Eplislon=0.09918368135888474. Q_Delta=0.004090781358893647\n",
      "Episode 462 finished after 4 timesteps. Eplislon=0.09868776295209031. Q_Delta=0.006204119695649907\n",
      "Episode 463 finished after 4 timesteps. Eplislon=0.09819432413732986. Q_Delta=0.002818739580905616\n",
      "Episode 464 finished after 4 timesteps. Eplislon=0.09770335251664321. Q_Delta=0.0023513829873642866\n",
      "Episode 465 finished after 3 timesteps. Eplislon=0.09721483575406. Q_Delta=0.0023186964178185665\n",
      "Episode 466 finished after 4 timesteps. Eplislon=0.09672876157528969. Q_Delta=0.0010918379337172546\n",
      "Episode 467 finished after 3 timesteps. Eplislon=0.09624511776741324. Q_Delta=0.006151726339902981\n",
      "Episode 468 finished after 4 timesteps. Eplislon=0.09576389217857617. Q_Delta=0.0022550169191769276\n",
      "Episode 469 finished after 2 timesteps. Eplislon=0.09528507271768329. Q_Delta=0.0033533749977256444\n",
      "Episode 470 finished after 4 timesteps. Eplislon=0.09480864735409487. Q_Delta=0.001465452260384581\n",
      "Episode 471 finished after 2 timesteps. Eplislon=0.0943346041173244. Q_Delta=0.002542785011991955\n",
      "Episode 472 finished after 1 timesteps. Eplislon=0.09386293109673778. Q_Delta=0.002300193120466698\n",
      "Episode 473 finished after 3 timesteps. Eplislon=0.09339361644125409. Q_Delta=0.002137783106619162\n",
      "Episode 474 finished after 6 timesteps. Eplislon=0.09292664835904782. Q_Delta=0.005544215601453961\n",
      "Episode 475 finished after 3 timesteps. Eplislon=0.09246201511725258. Q_Delta=0.002546407723244215\n",
      "Episode 476 finished after 1 timesteps. Eplislon=0.09199970504166631. Q_Delta=0.002024403315913359\n",
      "Episode 477 finished after 3 timesteps. Eplislon=0.09153970651645797. Q_Delta=0.0022017562034145253\n",
      "Episode 478 finished after 4 timesteps. Eplislon=0.09108200798387568. Q_Delta=0.0011410436872149599\n",
      "Episode 479 finished after 1 timesteps. Eplislon=0.0906265979439563. Q_Delta=0.001735974799068618\n",
      "Episode 480 finished after 4 timesteps. Eplislon=0.09017346495423652. Q_Delta=0.004897349615654661\n",
      "Episode 481 finished after 4 timesteps. Eplislon=0.08972259762946533. Q_Delta=0.007093472567299669\n",
      "Episode 482 finished after 3 timesteps. Eplislon=0.089273984641318. Q_Delta=0.011127273643578683\n",
      "Episode 483 finished after 3 timesteps. Eplislon=0.0888276147181114. Q_Delta=0.003559854742649119\n",
      "Episode 484 finished after 2 timesteps. Eplislon=0.08838347664452084. Q_Delta=0.007275308593644114\n",
      "Episode 485 finished after 4 timesteps. Eplislon=0.08794155926129824. Q_Delta=0.003398198048960188\n",
      "Episode 486 finished after 3 timesteps. Eplislon=0.08750185146499175. Q_Delta=0.005111601895020172\n",
      "Episode 487 finished after 5 timesteps. Eplislon=0.08706434220766679. Q_Delta=0.007041402633145344\n",
      "Episode 488 finished after 1 timesteps. Eplislon=0.08662902049662846. Q_Delta=0.0116652034410345\n",
      "Episode 489 finished after 6 timesteps. Eplislon=0.08619587539414532. Q_Delta=0.006619136115719533\n",
      "Episode 490 finished after 2 timesteps. Eplislon=0.08576489601717459. Q_Delta=0.003994015397620898\n",
      "Episode 491 finished after 4 timesteps. Eplislon=0.08533607153708872. Q_Delta=0.0024252074835882653\n",
      "Episode 492 finished after 4 timesteps. Eplislon=0.08490939117940327. Q_Delta=0.006984517273385088\n",
      "Episode 493 finished after 3 timesteps. Eplislon=0.08448484422350626. Q_Delta=0.006143861132673918\n",
      "Episode 494 finished after 2 timesteps. Eplislon=0.08406242000238873. Q_Delta=0.005999006559960218\n",
      "Episode 495 finished after 5 timesteps. Eplislon=0.08364210790237678. Q_Delta=0.0053442022335458365\n",
      "Episode 496 finished after 3 timesteps. Eplislon=0.0832238973628649. Q_Delta=0.008170939029160773\n",
      "Episode 497 finished after 6 timesteps. Eplislon=0.08280777787605056. Q_Delta=0.004235999261902046\n",
      "Episode 498 finished after 3 timesteps. Eplislon=0.08239373898667031. Q_Delta=0.007276093863878212\n",
      "Episode 499 finished after 5 timesteps. Eplislon=0.08198177029173696. Q_Delta=0.008858615150295379\n",
      "Episode 500 finished after 1 timesteps. Eplislon=0.08157186144027828. Q_Delta=0.014034177159656491\n",
      "Episode 501 finished after 4 timesteps. Eplislon=0.0811640021330769. Q_Delta=0.003080615020695787\n",
      "Episode 502 finished after 2 timesteps. Eplislon=0.08075818212241151. Q_Delta=0.003908925924602069\n",
      "Episode 503 finished after 1 timesteps. Eplislon=0.08035439121179945. Q_Delta=0.004599609163650653\n",
      "Episode 504 finished after 2 timesteps. Eplislon=0.07995261925574046. Q_Delta=0.006799259726271323\n",
      "Episode 505 finished after 4 timesteps. Eplislon=0.07955285615946175. Q_Delta=0.0032294674661936806\n",
      "Episode 506 finished after 5 timesteps. Eplislon=0.07915509187866444. Q_Delta=0.006294895885874885\n",
      "Episode 507 finished after 4 timesteps. Eplislon=0.07875931641927113. Q_Delta=0.002994424729282935\n",
      "Episode 508 finished after 6 timesteps. Eplislon=0.07836551983717477. Q_Delta=0.010517755883914718\n",
      "Episode 509 finished after 1 timesteps. Eplislon=0.07797369223798889. Q_Delta=0.0012826619400829742\n",
      "Episode 510 finished after 1 timesteps. Eplislon=0.07758382377679894. Q_Delta=0.002471246025566032\n",
      "Episode 511 finished after 3 timesteps. Eplislon=0.07719590465791494. Q_Delta=0.002319400805687377\n",
      "Episode 512 finished after 5 timesteps. Eplislon=0.07680992513462537. Q_Delta=0.007239150419992013\n",
      "Episode 513 finished after 4 timesteps. Eplislon=0.07642587550895225. Q_Delta=0.007522190880956792\n",
      "Episode 514 finished after 4 timesteps. Eplislon=0.07604374613140748. Q_Delta=0.008709172833232137\n",
      "Episode 515 finished after 2 timesteps. Eplislon=0.07566352740075044. Q_Delta=0.008781551171487378\n",
      "Episode 516 finished after 3 timesteps. Eplislon=0.07528520976374668. Q_Delta=0.005799413836211853\n",
      "Episode 517 finished after 3 timesteps. Eplislon=0.07490878371492794. Q_Delta=0.0018688755213907744\n",
      "Episode 518 finished after 4 timesteps. Eplislon=0.0745342397963533. Q_Delta=0.006347148367099514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 519 finished after 5 timesteps. Eplislon=0.07416156859737154. Q_Delta=0.007820365748267544\n",
      "Episode 520 finished after 4 timesteps. Eplislon=0.07379076075438468. Q_Delta=0.003470093738319663\n",
      "Episode 521 finished after 6 timesteps. Eplislon=0.07342180695061275. Q_Delta=0.004099684747838468\n",
      "Episode 522 finished after 1 timesteps. Eplislon=0.07305469791585968. Q_Delta=0.0032657335962373857\n",
      "Episode 523 finished after 1 timesteps. Eplislon=0.07268942442628039. Q_Delta=0.013344548639540488\n",
      "Episode 524 finished after 4 timesteps. Eplislon=0.07232597730414898. Q_Delta=0.003248868691335921\n",
      "Episode 525 finished after 1 timesteps. Eplislon=0.07196434741762824. Q_Delta=0.0015803164897327804\n",
      "Episode 526 finished after 3 timesteps. Eplislon=0.0716045256805401. Q_Delta=0.0007019124507892845\n",
      "Episode 527 finished after 3 timesteps. Eplislon=0.0712465030521374. Q_Delta=0.002087947934996078\n",
      "Episode 528 finished after 3 timesteps. Eplislon=0.0708902705368767. Q_Delta=0.0015626081626223993\n",
      "Episode 529 finished after 2 timesteps. Eplislon=0.07053581918419231. Q_Delta=0.0013369378588489744\n",
      "Episode 530 finished after 2 timesteps. Eplislon=0.07018314008827135. Q_Delta=0.005135630572071503\n",
      "Episode 531 finished after 3 timesteps. Eplislon=0.06983222438783. Q_Delta=0.0020832472282617718\n",
      "Episode 532 finished after 2 timesteps. Eplislon=0.06948306326589085. Q_Delta=0.001562353104258063\n",
      "Episode 533 finished after 4 timesteps. Eplislon=0.0691356479495614. Q_Delta=0.0085158426773434\n",
      "Episode 534 finished after 3 timesteps. Eplislon=0.06878996970981359. Q_Delta=0.00137200134335147\n",
      "Episode 535 finished after 3 timesteps. Eplislon=0.06844601986126451. Q_Delta=0.002360490698578762\n",
      "Episode 536 finished after 3 timesteps. Eplislon=0.06810378976195819. Q_Delta=0.0057196853932496294\n",
      "Episode 537 finished after 5 timesteps. Eplislon=0.0677632708131484. Q_Delta=0.004416256359663406\n",
      "Episode 538 finished after 4 timesteps. Eplislon=0.06742445445908266. Q_Delta=0.0046106423651514905\n",
      "Episode 539 finished after 10 timesteps. Eplislon=0.06708733218678724. Q_Delta=0.0038429227685381597\n",
      "Episode 540 finished after 3 timesteps. Eplislon=0.0667518955258533. Q_Delta=0.00820470412545223\n",
      "Episode 541 finished after 1 timesteps. Eplislon=0.06641813604822402. Q_Delta=0.011234283101726916\n",
      "Episode 542 finished after 3 timesteps. Eplislon=0.0660860453679829. Q_Delta=0.0034298826244773726\n",
      "Episode 543 finished after 3 timesteps. Eplislon=0.06575561514114299. Q_Delta=0.0032204375106472303\n",
      "Episode 544 finished after 5 timesteps. Eplislon=0.06542683706543727. Q_Delta=0.008219155325951254\n",
      "Episode 545 finished after 4 timesteps. Eplislon=0.06509970288011008. Q_Delta=0.005642143329408322\n",
      "Episode 546 finished after 3 timesteps. Eplislon=0.06477420436570952. Q_Delta=0.0029148878395171365\n",
      "Episode 547 finished after 1 timesteps. Eplislon=0.06445033334388098. Q_Delta=0.001976736898631981\n",
      "Episode 548 finished after 3 timesteps. Eplislon=0.06412808167716157. Q_Delta=0.0008224472491796068\n",
      "Episode 549 finished after 2 timesteps. Eplislon=0.06380744126877576. Q_Delta=0.0018371273944501887\n",
      "Episode 550 finished after 2 timesteps. Eplislon=0.06348840406243188. Q_Delta=0.00206406740573023\n",
      "Episode 551 finished after 4 timesteps. Eplislon=0.06317096204211972. Q_Delta=0.005023959785912746\n",
      "Episode 552 finished after 1 timesteps. Eplislon=0.06285510723190912. Q_Delta=0.008434199999885594\n",
      "Episode 553 finished after 2 timesteps. Eplislon=0.06254083169574957. Q_Delta=0.0028800025423196818\n",
      "Episode 554 finished after 2 timesteps. Eplislon=0.062228127537270826. Q_Delta=0.002345553628587682\n",
      "Episode 555 finished after 5 timesteps. Eplislon=0.06191698689958447. Q_Delta=0.0033825322317294626\n",
      "Episode 556 finished after 1 timesteps. Eplislon=0.061607401965086545. Q_Delta=0.00666472313777533\n",
      "Episode 557 finished after 5 timesteps. Eplislon=0.06129936495526111. Q_Delta=0.003314049215395953\n",
      "Episode 558 finished after 5 timesteps. Eplislon=0.0609928681304848. Q_Delta=0.0018304866623183535\n",
      "Episode 559 finished after 4 timesteps. Eplislon=0.060687903789832374. Q_Delta=0.008322935412976046\n",
      "Episode 560 finished after 2 timesteps. Eplislon=0.06038446427088321. Q_Delta=0.0050474512430193075\n",
      "Episode 561 finished after 2 timesteps. Eplislon=0.06008254194952879. Q_Delta=0.00499787526736134\n",
      "Episode 562 finished after 3 timesteps. Eplislon=0.05978212923978115. Q_Delta=0.0039292197012101475\n",
      "Episode 563 finished after 1 timesteps. Eplislon=0.05948321859358224. Q_Delta=0.0006360900582769169\n",
      "Episode 564 finished after 4 timesteps. Eplislon=0.05918580250061433. Q_Delta=0.0022038740651439404\n",
      "Episode 565 finished after 2 timesteps. Eplislon=0.058889873488111255. Q_Delta=0.005539515109910631\n",
      "Episode 566 finished after 2 timesteps. Eplislon=0.058595424120670696. Q_Delta=0.000990090312602998\n",
      "Episode 567 finished after 7 timesteps. Eplislon=0.05830244700006734. Q_Delta=0.009237337869991733\n",
      "Episode 568 finished after 1 timesteps. Eplislon=0.058010934765067. Q_Delta=0.00888853626757502\n",
      "Episode 569 finished after 3 timesteps. Eplislon=0.05772088009124167. Q_Delta=0.006445543319881082\n",
      "Episode 570 finished after 4 timesteps. Eplislon=0.05743227569078546. Q_Delta=0.006362894144315595\n",
      "Episode 571 finished after 1 timesteps. Eplislon=0.05714511431233153. Q_Delta=0.0015142867151889394\n",
      "Episode 572 finished after 4 timesteps. Eplislon=0.05685938874076987. Q_Delta=0.004563927150472574\n",
      "Episode 573 finished after 3 timesteps. Eplislon=0.056575091797066025. Q_Delta=0.003616064180404647\n",
      "Episode 574 finished after 3 timesteps. Eplislon=0.056292216338080694. Q_Delta=0.004108339174013764\n",
      "Episode 575 finished after 7 timesteps. Eplislon=0.05601075525639029. Q_Delta=0.006747124832276162\n",
      "Episode 576 finished after 1 timesteps. Eplislon=0.05573070148010834. Q_Delta=0.008140411521650126\n",
      "Episode 577 finished after 1 timesteps. Eplislon=0.0554520479727078. Q_Delta=0.0074343121735394035\n",
      "Episode 578 finished after 3 timesteps. Eplislon=0.05517478773284426. Q_Delta=0.00790149542059515\n",
      "Episode 579 finished after 3 timesteps. Eplislon=0.05489891379418004. Q_Delta=0.0058915704861678036\n",
      "Episode 580 finished after 2 timesteps. Eplislon=0.05462441922520914. Q_Delta=0.004458093787363782\n",
      "Episode 581 finished after 1 timesteps. Eplislon=0.0543512971290831. Q_Delta=0.0068229128689183405\n",
      "Episode 582 finished after 5 timesteps. Eplislon=0.05407954064343768. Q_Delta=0.006176940090426864\n",
      "Episode 583 finished after 3 timesteps. Eplislon=0.05380914294022049. Q_Delta=0.003059652110966556\n",
      "Episode 584 finished after 4 timesteps. Eplislon=0.05354009722551939. Q_Delta=0.006606209062091362\n",
      "Episode 585 finished after 4 timesteps. Eplislon=0.05327239673939179. Q_Delta=0.004153036710310615\n",
      "Episode 586 finished after 3 timesteps. Eplislon=0.053006034755694834. Q_Delta=0.0016540773908419275\n",
      "Episode 587 finished after 4 timesteps. Eplislon=0.052741004581916356. Q_Delta=0.0026770597941775387\n",
      "Episode 588 finished after 4 timesteps. Eplislon=0.052477299559006776. Q_Delta=0.0017718174906674877\n",
      "Episode 589 finished after 7 timesteps. Eplislon=0.052214913061211746. Q_Delta=0.007476141557577587\n",
      "Episode 590 finished after 2 timesteps. Eplislon=0.05195383849590569. Q_Delta=0.0022969259084426596\n",
      "Episode 591 finished after 2 timesteps. Eplislon=0.05169406930342616. Q_Delta=0.003261099524038691\n",
      "Episode 592 finished after 6 timesteps. Eplislon=0.05143559895690903. Q_Delta=0.005233698828986018\n",
      "Episode 593 finished after 2 timesteps. Eplislon=0.051178420962124486. Q_Delta=0.0020926760444440196\n",
      "Episode 594 finished after 5 timesteps. Eplislon=0.05092252885731386. Q_Delta=0.00566605375247522\n",
      "Episode 595 finished after 2 timesteps. Eplislon=0.05066791621302729. Q_Delta=0.00405383590327868\n",
      "Episode 596 finished after 3 timesteps. Eplislon=0.05041457663196215. Q_Delta=0.004637848083246521\n",
      "Episode 597 finished after 4 timesteps. Eplislon=0.050162503748802344. Q_Delta=0.006972383541953647\n",
      "Episode 598 finished after 4 timesteps. Eplislon=0.049911691230058335. Q_Delta=0.003478590847803803\n",
      "Episode 599 finished after 3 timesteps. Eplislon=0.04966213277390804. Q_Delta=0.0042015550343411645\n",
      "Episode 600 finished after 2 timesteps. Eplislon=0.0494138221100385. Q_Delta=0.00871464216604273\n",
      "Episode 601 finished after 7 timesteps. Eplislon=0.04916675299948831. Q_Delta=0.0071487734944904536\n",
      "Episode 602 finished after 2 timesteps. Eplislon=0.04892091923449087. Q_Delta=0.004244737675942578\n",
      "Episode 603 finished after 3 timesteps. Eplislon=0.04867631463831842. Q_Delta=0.0050618215803877415\n",
      "Episode 604 finished after 5 timesteps. Eplislon=0.048432933065126825. Q_Delta=0.006528503884987135\n",
      "Episode 605 finished after 1 timesteps. Eplislon=0.048190768399801194. Q_Delta=0.006151658153357609\n",
      "Episode 606 finished after 3 timesteps. Eplislon=0.04794981455780219. Q_Delta=0.0025478267661528387\n",
      "Episode 607 finished after 6 timesteps. Eplislon=0.04771006548501318. Q_Delta=0.0060847335805297624\n",
      "Episode 608 finished after 3 timesteps. Eplislon=0.047471515157588115. Q_Delta=0.0033565094368932145\n",
      "Episode 609 finished after 5 timesteps. Eplislon=0.047234157581800176. Q_Delta=0.00261652475247931\n",
      "Episode 610 finished after 2 timesteps. Eplislon=0.046997986793891174. Q_Delta=0.004917244129449716\n",
      "Episode 611 finished after 1 timesteps. Eplislon=0.04676299685992172. Q_Delta=0.002325043288572637\n",
      "Episode 612 finished after 2 timesteps. Eplislon=0.04652918187562211. Q_Delta=0.005061176528778744\n",
      "Episode 613 finished after 1 timesteps. Eplislon=0.046296535966244. Q_Delta=0.0006027398461380118\n",
      "Episode 614 finished after 3 timesteps. Eplislon=0.046065053286412784. Q_Delta=0.001431711715155955\n",
      "Episode 615 finished after 3 timesteps. Eplislon=0.04583472801998072. Q_Delta=0.0034986223074283673\n",
      "Episode 616 finished after 4 timesteps. Eplislon=0.045605554379880814. Q_Delta=0.003604297708345694\n",
      "Episode 617 finished after 2 timesteps. Eplislon=0.04537752660798141. Q_Delta=0.0010679417501817667\n",
      "Episode 618 finished after 3 timesteps. Eplislon=0.0451506389749415. Q_Delta=0.002808358741074953\n",
      "Episode 619 finished after 1 timesteps. Eplislon=0.044924885780066794. Q_Delta=0.0033504313271341957\n",
      "Episode 620 finished after 3 timesteps. Eplislon=0.04470026135116646. Q_Delta=0.0019780231155173875\n",
      "Episode 621 finished after 4 timesteps. Eplislon=0.04447676004441063. Q_Delta=0.004841224813038725\n",
      "Episode 622 finished after 3 timesteps. Eplislon=0.04425437624418858. Q_Delta=0.0023482512943993803\n",
      "Episode 623 finished after 2 timesteps. Eplislon=0.04403310436296763. Q_Delta=0.0027656307887887754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 624 finished after 3 timesteps. Eplislon=0.043812938841152796. Q_Delta=0.0014546705271606026\n",
      "Episode 625 finished after 2 timesteps. Eplislon=0.04359387414694703. Q_Delta=0.004487296075013136\n",
      "Episode 626 finished after 2 timesteps. Eplislon=0.043375904776212296. Q_Delta=0.0013796267009917873\n",
      "Episode 627 finished after 1 timesteps. Eplislon=0.043159025252331236. Q_Delta=0.003332468132373867\n",
      "Episode 628 finished after 3 timesteps. Eplislon=0.04294323012606958. Q_Delta=0.0032566359533100497\n",
      "Episode 629 finished after 4 timesteps. Eplislon=0.04272851397543923. Q_Delta=0.0021325069799648655\n",
      "Episode 630 finished after 3 timesteps. Eplislon=0.04251487140556204. Q_Delta=0.003125126083971789\n",
      "Episode 631 finished after 3 timesteps. Eplislon=0.04230229704853423. Q_Delta=0.0028147055330015234\n",
      "Episode 632 finished after 1 timesteps. Eplislon=0.04209078556329156. Q_Delta=0.0017723014944238669\n",
      "Episode 633 finished after 6 timesteps. Eplislon=0.0418803316354751. Q_Delta=0.002384112364453239\n",
      "Episode 634 finished after 3 timesteps. Eplislon=0.041670929977297724. Q_Delta=0.004128021937724213\n",
      "Episode 635 finished after 4 timesteps. Eplislon=0.04146257532741124. Q_Delta=0.003388712683235484\n",
      "Episode 636 finished after 3 timesteps. Eplislon=0.04125526245077418. Q_Delta=0.0046763328434276845\n",
      "Episode 637 finished after 4 timesteps. Eplislon=0.04104898613852031. Q_Delta=0.001015901846593087\n",
      "Episode 638 finished after 6 timesteps. Eplislon=0.04084374120782771. Q_Delta=0.002056909248108585\n",
      "Episode 639 finished after 4 timesteps. Eplislon=0.04063952250178857. Q_Delta=0.0021777080796901993\n",
      "Episode 640 finished after 5 timesteps. Eplislon=0.04043632488927963. Q_Delta=0.002827513869500975\n",
      "Episode 641 finished after 5 timesteps. Eplislon=0.04023414326483323. Q_Delta=0.0021296187527111822\n",
      "Episode 642 finished after 5 timesteps. Eplislon=0.040032972548509065. Q_Delta=0.0024097472892161908\n",
      "Episode 643 finished after 5 timesteps. Eplislon=0.03983280768576652. Q_Delta=0.0013642554800939565\n",
      "Episode 644 finished after 5 timesteps. Eplislon=0.03963364364733769. Q_Delta=0.002313164097803333\n",
      "Episode 645 finished after 4 timesteps. Eplislon=0.039435475429100995. Q_Delta=0.0061131310667124905\n",
      "Episode 646 finished after 4 timesteps. Eplislon=0.03923829805195549. Q_Delta=0.0018975939399661634\n",
      "Episode 647 finished after 5 timesteps. Eplislon=0.03904210656169572. Q_Delta=0.002603042119470689\n",
      "Episode 648 finished after 5 timesteps. Eplislon=0.03884689602888724. Q_Delta=0.002108954598230528\n",
      "Episode 649 finished after 5 timesteps. Eplislon=0.0386526615487428. Q_Delta=0.003561846652297684\n",
      "Episode 650 finished after 5 timesteps. Eplislon=0.03845939824099909. Q_Delta=0.0037258842010258197\n",
      "Episode 651 finished after 2 timesteps. Eplislon=0.03826710124979409. Q_Delta=0.004451365925832562\n",
      "Episode 652 finished after 1 timesteps. Eplislon=0.038075765743545126. Q_Delta=0.005304026718905397\n",
      "Episode 653 finished after 3 timesteps. Eplislon=0.0378853869148274. Q_Delta=0.0025923815328830666\n",
      "Episode 654 finished after 3 timesteps. Eplislon=0.03769595998025326. Q_Delta=0.0010637792880705172\n",
      "Episode 655 finished after 4 timesteps. Eplislon=0.03750748018035199. Q_Delta=0.002646850277105234\n",
      "Episode 656 finished after 3 timesteps. Eplislon=0.037319942779450235. Q_Delta=0.005788671143036754\n",
      "Episode 657 finished after 3 timesteps. Eplislon=0.037133343065552986. Q_Delta=0.0035522839167888196\n",
      "Episode 658 finished after 3 timesteps. Eplislon=0.03694767635022522. Q_Delta=0.0036833681519608716\n",
      "Episode 659 finished after 3 timesteps. Eplislon=0.036762937968474095. Q_Delta=0.0014704225819319738\n",
      "Episode 660 finished after 3 timesteps. Eplislon=0.03657912327863173. Q_Delta=0.0008784252431438544\n",
      "Episode 661 finished after 3 timesteps. Eplislon=0.036396227662238566. Q_Delta=0.004097019715978238\n",
      "Episode 662 finished after 4 timesteps. Eplislon=0.03621424652392737. Q_Delta=0.002253797876061503\n",
      "Episode 663 finished after 1 timesteps. Eplislon=0.036033175291307735. Q_Delta=0.004602560100334774\n",
      "Episode 664 finished after 1 timesteps. Eplislon=0.03585300941485119. Q_Delta=0.0024200363077642173\n",
      "Episode 665 finished after 2 timesteps. Eplislon=0.035673744367776934. Q_Delta=0.0029255012611064113\n",
      "Episode 666 finished after 3 timesteps. Eplislon=0.03549537564593805. Q_Delta=0.0017591621586489081\n",
      "Episode 667 finished after 2 timesteps. Eplislon=0.035317898767708356. Q_Delta=0.0009597695988016741\n",
      "Episode 668 finished after 2 timesteps. Eplislon=0.03514130927386981. Q_Delta=0.0019323881044105429\n",
      "Episode 669 finished after 3 timesteps. Eplislon=0.03496560272750046. Q_Delta=0.0033744237455707315\n",
      "Episode 670 finished after 3 timesteps. Eplislon=0.03479077471386296. Q_Delta=0.0031272290845657156\n",
      "Episode 671 finished after 2 timesteps. Eplislon=0.03461682084029365. Q_Delta=0.0025967566029225786\n",
      "Episode 672 finished after 4 timesteps. Eplislon=0.034443736736092176. Q_Delta=0.002755342536207961\n",
      "Episode 673 finished after 2 timesteps. Eplislon=0.034271518052411715. Q_Delta=0.0009940938648299036\n",
      "Episode 674 finished after 3 timesteps. Eplislon=0.034100160462149656. Q_Delta=0.0018197494283252273\n",
      "Episode 675 finished after 2 timesteps. Eplislon=0.03392965965983891. Q_Delta=0.001453922047396916\n",
      "Episode 676 finished after 3 timesteps. Eplislon=0.033760011361539714. Q_Delta=0.0024479142690114384\n",
      "Episode 677 finished after 1 timesteps. Eplislon=0.03359121130473201. Q_Delta=0.0005854191030001399\n",
      "Episode 678 finished after 5 timesteps. Eplislon=0.033423255248208356. Q_Delta=0.0019504942904402301\n",
      "Episode 679 finished after 2 timesteps. Eplislon=0.03325613897196732. Q_Delta=0.0008035463253987518\n",
      "Episode 680 finished after 2 timesteps. Eplislon=0.03308985827710748. Q_Delta=0.0007752230393653914\n",
      "Episode 681 finished after 3 timesteps. Eplislon=0.032924408985721944. Q_Delta=0.0008880355030147872\n",
      "Episode 682 finished after 1 timesteps. Eplislon=0.03275978694079333. Q_Delta=0.00020932418362207272\n",
      "Episode 683 finished after 1 timesteps. Eplislon=0.032595988006089364. Q_Delta=0.0005316898589211583\n",
      "Episode 684 finished after 4 timesteps. Eplislon=0.032433008066058915. Q_Delta=0.00071281677110549\n",
      "Episode 685 finished after 6 timesteps. Eplislon=0.03227084302572862. Q_Delta=0.0019488251334162283\n",
      "Episode 686 finished after 2 timesteps. Eplislon=0.032109488810599975. Q_Delta=0.0003706726454704712\n",
      "Episode 687 finished after 4 timesteps. Eplislon=0.031948941366546975. Q_Delta=0.010200177444904923\n",
      "Episode 688 finished after 2 timesteps. Eplislon=0.03178919665971424. Q_Delta=0.004436981435127607\n",
      "Episode 689 finished after 5 timesteps. Eplislon=0.03163025067641567. Q_Delta=0.004377169685584881\n",
      "Episode 690 finished after 1 timesteps. Eplislon=0.03147209942303359. Q_Delta=0.01027276201442373\n",
      "Episode 691 finished after 2 timesteps. Eplislon=0.03131473892591842. Q_Delta=0.004239420987844356\n",
      "Episode 692 finished after 2 timesteps. Eplislon=0.031158165231288826. Q_Delta=0.0009636875650759769\n",
      "Episode 693 finished after 1 timesteps. Eplislon=0.03100237440513238. Q_Delta=0.004579337518768489\n",
      "Episode 694 finished after 6 timesteps. Eplislon=0.030847362533106718. Q_Delta=0.004964609238060025\n",
      "Episode 695 finished after 5 timesteps. Eplislon=0.030693125720441184. Q_Delta=0.0030536006912136315\n",
      "Episode 696 finished after 1 timesteps. Eplislon=0.030539660091838977. Q_Delta=0.005447375664415555\n",
      "Episode 697 finished after 2 timesteps. Eplislon=0.03038696179137978. Q_Delta=0.003233588845657387\n",
      "Episode 698 finished after 3 timesteps. Eplislon=0.030235026982422884. Q_Delta=0.002568645614709338\n",
      "Episode 699 finished after 2 timesteps. Eplislon=0.030083851847510768. Q_Delta=0.018547818742732092\n",
      "Episode 700 finished after 4 timesteps. Eplislon=0.029933432588273214. Q_Delta=0.0038879014126813882\n",
      "Episode 701 finished after 3 timesteps. Eplislon=0.029783765425331846. Q_Delta=0.0017437279534778805\n",
      "Episode 702 finished after 4 timesteps. Eplislon=0.029634846598205186. Q_Delta=0.0036331873744770704\n",
      "Episode 703 finished after 4 timesteps. Eplislon=0.02948667236521416. Q_Delta=0.005363151715691017\n",
      "Episode 704 finished after 1 timesteps. Eplislon=0.029339239003388088. Q_Delta=0.003167659196320338\n",
      "Episode 705 finished after 1 timesteps. Eplislon=0.029192542808371146. Q_Delta=0.002875116099133157\n",
      "Episode 706 finished after 1 timesteps. Eplislon=0.02904658009432929. Q_Delta=0.0019201874704666277\n",
      "Episode 707 finished after 3 timesteps. Eplislon=0.028901347193857643. Q_Delta=0.00204016451034413\n",
      "Episode 708 finished after 2 timesteps. Eplislon=0.028756840457888354. Q_Delta=0.0028949750215130354\n",
      "Episode 709 finished after 3 timesteps. Eplislon=0.02861305625559891. Q_Delta=0.0028042889996554576\n",
      "Episode 710 finished after 4 timesteps. Eplislon=0.028469990974320916. Q_Delta=0.0016162067965453109\n",
      "Episode 711 finished after 5 timesteps. Eplislon=0.02832764101944931. Q_Delta=0.00449407296155444\n",
      "Episode 712 finished after 6 timesteps. Eplislon=0.028186002814352063. Q_Delta=0.0037185965624852804\n",
      "Episode 713 finished after 5 timesteps. Eplislon=0.0280450728002803. Q_Delta=0.0029732488022227387\n",
      "Episode 714 finished after 6 timesteps. Eplislon=0.0279048474362789. Q_Delta=0.010802865871406886\n",
      "Episode 715 finished after 2 timesteps. Eplislon=0.027765323199097504. Q_Delta=0.014834738890151078\n",
      "Episode 716 finished after 5 timesteps. Eplislon=0.027626496583102015. Q_Delta=0.009227624734920314\n",
      "Episode 717 finished after 6 timesteps. Eplislon=0.027488364100186506. Q_Delta=0.007703072058801534\n",
      "Episode 718 finished after 5 timesteps. Eplislon=0.027350922279685573. Q_Delta=0.004120688020141294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 719 finished after 6 timesteps. Eplislon=0.027214167668287145. Q_Delta=0.004895127901852907\n",
      "Episode 720 finished after 2 timesteps. Eplislon=0.02707809682994571. Q_Delta=0.00856036716100228\n",
      "Episode 721 finished after 1 timesteps. Eplislon=0.02694270634579598. Q_Delta=0.0065264251840333465\n",
      "Episode 722 finished after 3 timesteps. Eplislon=0.026807992814067. Q_Delta=0.002512195086742756\n",
      "Episode 723 finished after 18 timesteps. Eplislon=0.026673952849996664. Q_Delta=0.01879972856137302\n",
      "Episode 724 finished after 5 timesteps. Eplislon=0.02654058308574668. Q_Delta=0.009240225185856588\n",
      "Episode 725 finished after 5 timesteps. Eplislon=0.026407880170317945. Q_Delta=0.004642761409249197\n",
      "Episode 726 finished after 1 timesteps. Eplislon=0.026275840769466357. Q_Delta=0.012768441817741838\n",
      "Episode 727 finished after 2 timesteps. Eplislon=0.026144461565619025. Q_Delta=0.01451903071060151\n",
      "Episode 728 finished after 2 timesteps. Eplislon=0.02601373925779093. Q_Delta=0.0034511315742916104\n",
      "Episode 729 finished after 565 timesteps. Eplislon=0.025883670561501974. Q_Delta=0.0036816489347899304\n",
      "Episode 730 finished after 4 timesteps. Eplislon=0.025754252208694463. Q_Delta=0.035976072702966766\n",
      "Episode 731 finished after 2 timesteps. Eplislon=0.02562548094765099. Q_Delta=0.014110027951067583\n",
      "Episode 732 finished after 4 timesteps. Eplislon=0.025497353542912736. Q_Delta=0.021619324033855747\n",
      "Episode 733 finished after 329 timesteps. Eplislon=0.02536986677519817. Q_Delta=0.0034308423267726484\n",
      "Episode 734 finished after 1 timesteps. Eplislon=0.02524301744132218. Q_Delta=0.03984976624359571\n",
      "Episode 735 finished after 3 timesteps. Eplislon=0.025116802354115567. Q_Delta=0.043249138492820895\n",
      "Episode 736 finished after 2 timesteps. Eplislon=0.024991218342344988. Q_Delta=0.04233280092170888\n",
      "Episode 737 finished after 3 timesteps. Eplislon=0.024866262250633264. Q_Delta=0.030849626154046256\n",
      "Episode 738 finished after 5 timesteps. Eplislon=0.024741930939380097. Q_Delta=0.010089572981492888\n",
      "Episode 739 finished after 1000 timesteps. Eplislon=0.024618221284683196. Q_Delta=0.004652742654014981\n",
      "Episode 740 finished after 4 timesteps. Eplislon=0.02449513017825978. Q_Delta=0.08914899469459908\n",
      "Episode 741 finished after 2 timesteps. Eplislon=0.02437265452736848. Q_Delta=0.09058564011922399\n",
      "Episode 742 finished after 567 timesteps. Eplislon=0.024250791254731636. Q_Delta=0.008975874296930121\n",
      "Episode 743 finished after 1000 timesteps. Eplislon=0.024129537298457977. Q_Delta=0.004793780815417371\n",
      "Episode 744 finished after 2 timesteps. Eplislon=0.024008889611965685. Q_Delta=0.03248551562132579\n",
      "Episode 745 finished after 5 timesteps. Eplislon=0.023888845163905856. Q_Delta=0.028651355229534835\n",
      "Episode 746 finished after 2 timesteps. Eplislon=0.023769400938086327. Q_Delta=0.027872162749328244\n",
      "Episode 747 finished after 3 timesteps. Eplislon=0.023650553933395897. Q_Delta=0.04597984857124019\n",
      "Episode 748 finished after 1 timesteps. Eplislon=0.023532301163728918. Q_Delta=0.024721471284361307\n",
      "Episode 749 finished after 357 timesteps. Eplislon=0.023414639657910272. Q_Delta=0.0026754517251884853\n",
      "Episode 750 finished after 5 timesteps. Eplislon=0.023297566459620722. Q_Delta=0.039808944332743554\n",
      "Episode 751 finished after 1 timesteps. Eplislon=0.023181078627322618. Q_Delta=0.045032899210246224\n",
      "Episode 752 finished after 2 timesteps. Eplislon=0.023065173234186005. Q_Delta=0.04211987510519738\n",
      "Episode 753 finished after 93 timesteps. Eplislon=0.022949847368015076. Q_Delta=0.007918783722080009\n",
      "Episode 754 finished after 3 timesteps. Eplislon=0.022835098131175. Q_Delta=0.1324200090593365\n",
      "Episode 755 finished after 4 timesteps. Eplislon=0.022720922640519125. Q_Delta=0.07172903089388497\n",
      "Episode 756 finished after 41 timesteps. Eplislon=0.02260731802731653. Q_Delta=0.02568157352969304\n",
      "Episode 757 finished after 1000 timesteps. Eplislon=0.022494281437179946. Q_Delta=0.004203111654408146\n",
      "Episode 758 finished after 4 timesteps. Eplislon=0.022381810029994047. Q_Delta=0.08912884542783059\n",
      "Episode 759 finished after 152 timesteps. Eplislon=0.022269900979844076. Q_Delta=0.00572776747820897\n",
      "Episode 760 finished after 3 timesteps. Eplislon=0.022158551474944856. Q_Delta=0.042808250863571685\n",
      "Episode 761 finished after 5 timesteps. Eplislon=0.022047758717570132. Q_Delta=0.04963349011484182\n",
      "Episode 762 finished after 4 timesteps. Eplislon=0.021937519923982282. Q_Delta=0.026249055781325886\n",
      "Episode 763 finished after 6 timesteps. Eplislon=0.021827832324362372. Q_Delta=0.05310427863759165\n",
      "Episode 764 finished after 26 timesteps. Eplislon=0.02171869316274056. Q_Delta=0.030194228233157896\n",
      "Episode 765 finished after 4 timesteps. Eplislon=0.021610099696926857. Q_Delta=0.05875302070563429\n",
      "Episode 766 finished after 2 timesteps. Eplislon=0.021502049198442223. Q_Delta=0.08850342155972835\n",
      "Episode 767 finished after 4 timesteps. Eplislon=0.021394538952450012. Q_Delta=0.046688107921172894\n",
      "Episode 768 finished after 2 timesteps. Eplislon=0.02128756625768776. Q_Delta=0.061868169065506184\n",
      "Episode 769 finished after 4 timesteps. Eplislon=0.021181128426399323. Q_Delta=0.03579802679926783\n",
      "Episode 770 finished after 2 timesteps. Eplislon=0.021075222784267326. Q_Delta=0.02288732304910468\n",
      "Episode 771 finished after 876 timesteps. Eplislon=0.020969846670345987. Q_Delta=0.0038335499329298153\n",
      "Episode 772 finished after 1 timesteps. Eplislon=0.020864997436994256. Q_Delta=0.0004536774534065202\n",
      "Episode 773 finished after 2 timesteps. Eplislon=0.020760672449809284. Q_Delta=0.04432423116393258\n",
      "Episode 774 finished after 4 timesteps. Eplislon=0.020656869087560238. Q_Delta=0.01895890291883584\n",
      "Episode 775 finished after 7 timesteps. Eplislon=0.020553584742122436. Q_Delta=0.013327602203794428\n",
      "Episode 776 finished after 5 timesteps. Eplislon=0.020450816818411825. Q_Delta=0.016042911315968512\n",
      "Episode 777 finished after 1 timesteps. Eplislon=0.020348562734319765. Q_Delta=0.02426163854423835\n",
      "Episode 778 finished after 2 timesteps. Eplislon=0.020246819920648168. Q_Delta=0.0453296590157235\n",
      "Episode 779 finished after 1 timesteps. Eplislon=0.020145585821044927. Q_Delta=0.01301237156185242\n",
      "Episode 780 finished after 4 timesteps. Eplislon=0.020044857891939702. Q_Delta=0.03296050503470355\n",
      "Episode 781 finished after 6 timesteps. Eplislon=0.019944633602480003. Q_Delta=0.026258578734726607\n",
      "Episode 782 finished after 4 timesteps. Eplislon=0.019844910434467605. Q_Delta=0.009381117187024973\n",
      "Episode 783 finished after 5 timesteps. Eplislon=0.019745685882295267. Q_Delta=0.024312991003586703\n",
      "Episode 784 finished after 2 timesteps. Eplislon=0.01964695745288379. Q_Delta=0.016112802212089217\n",
      "Episode 785 finished after 3 timesteps. Eplislon=0.01954872266561937. Q_Delta=0.010410344569037333\n",
      "Episode 786 finished after 3 timesteps. Eplislon=0.019450979052291272. Q_Delta=0.023398623465281137\n",
      "Episode 787 finished after 2 timesteps. Eplislon=0.019353724157029815. Q_Delta=0.029633656790644503\n",
      "Episode 788 finished after 4 timesteps. Eplislon=0.019256955536244666. Q_Delta=0.012404532985281935\n",
      "Episode 789 finished after 5 timesteps. Eplislon=0.019160670758563442. Q_Delta=0.010877637811262608\n",
      "Episode 790 finished after 1 timesteps. Eplislon=0.019064867404770626. Q_Delta=5.348508792224482e-05\n",
      "Episode 791 finished after 4 timesteps. Eplislon=0.018969543067746772. Q_Delta=0.015361013714046662\n",
      "Episode 792 finished after 1 timesteps. Eplislon=0.018874695352408037. Q_Delta=0.0031999916277469787\n",
      "Episode 793 finished after 4 timesteps. Eplislon=0.018780321875645996. Q_Delta=0.01112911146159487\n",
      "Episode 794 finished after 3 timesteps. Eplislon=0.018686420266267767. Q_Delta=0.018294043242241858\n",
      "Episode 795 finished after 3 timesteps. Eplislon=0.018592988164936427. Q_Delta=0.0058958689028698235\n",
      "Episode 796 finished after 1 timesteps. Eplislon=0.018500023224111744. Q_Delta=0.017400212022074424\n",
      "Episode 797 finished after 2 timesteps. Eplislon=0.018407523107991184. Q_Delta=0.007936341949171477\n",
      "Episode 798 finished after 3 timesteps. Eplislon=0.01831548549245123. Q_Delta=0.008735690923754294\n",
      "Episode 799 finished after 5 timesteps. Eplislon=0.018223908064988973. Q_Delta=0.011867502660767703\n",
      "Episode 800 finished after 7 timesteps. Eplislon=0.018132788524664028. Q_Delta=0.01094241463858254\n",
      "Episode 801 finished after 2 timesteps. Eplislon=0.018042124582040707. Q_Delta=0.018394294387452104\n",
      "Episode 802 finished after 5 timesteps. Eplislon=0.017951913959130504. Q_Delta=0.005037152607781525\n",
      "Episode 803 finished after 3 timesteps. Eplislon=0.01786215438933485. Q_Delta=0.011241015156623754\n",
      "Episode 804 finished after 5 timesteps. Eplislon=0.017772843617388175. Q_Delta=0.011808146081271054\n",
      "Episode 805 finished after 4 timesteps. Eplislon=0.017683979399301233. Q_Delta=0.01025642403169294\n",
      "Episode 806 finished after 2 timesteps. Eplislon=0.017595559502304726. Q_Delta=0.004008743830598904\n",
      "Episode 807 finished after 4 timesteps. Eplislon=0.0175075817047932. Q_Delta=0.004368149810800498\n",
      "Episode 808 finished after 3 timesteps. Eplislon=0.017420043796269234. Q_Delta=0.0031813255948290133\n",
      "Episode 809 finished after 4 timesteps. Eplislon=0.017332943577287888. Q_Delta=0.004293765428997426\n",
      "Episode 810 finished after 3 timesteps. Eplislon=0.01724627885940145. Q_Delta=0.011730338344359622\n",
      "Episode 811 finished after 1 timesteps. Eplislon=0.017160047465104442. Q_Delta=0.003915735907215501\n",
      "Episode 812 finished after 4 timesteps. Eplislon=0.01707424722777892. Q_Delta=0.003449167048386992\n",
      "Episode 813 finished after 3 timesteps. Eplislon=0.016988875991640028. Q_Delta=0.0034633330880887345\n",
      "Episode 814 finished after 5 timesteps. Eplislon=0.016903931611681827. Q_Delta=0.00934971402007354\n",
      "Episode 815 finished after 3 timesteps. Eplislon=0.01681941195362342. Q_Delta=0.005884095452896883\n",
      "Episode 816 finished after 4 timesteps. Eplislon=0.016735314893855303. Q_Delta=0.002893466953346663\n",
      "Episode 817 finished after 2 timesteps. Eplislon=0.016651638319386028. Q_Delta=0.0032382194533296937\n",
      "Episode 818 finished after 4 timesteps. Eplislon=0.0165683801277891. Q_Delta=0.01486601372002544\n",
      "Episode 819 finished after 4 timesteps. Eplislon=0.016485538227150154. Q_Delta=0.004002384916814233\n",
      "Episode 820 finished after 6 timesteps. Eplislon=0.0164031105360144. Q_Delta=0.017240456435794343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 821 finished after 3 timesteps. Eplislon=0.01632109498333433. Q_Delta=0.012697607657368678\n",
      "Episode 822 finished after 2 timesteps. Eplislon=0.016239489508417658. Q_Delta=0.010592762486057838\n",
      "Episode 823 finished after 3 timesteps. Eplislon=0.01615829206087557. Q_Delta=0.011632140584848924\n",
      "Episode 824 finished after 5 timesteps. Eplislon=0.01607750060057119. Q_Delta=0.007456593520653976\n",
      "Episode 825 finished after 1 timesteps. Eplislon=0.015997113097568336. Q_Delta=0.011308076422018587\n",
      "Episode 826 finished after 4 timesteps. Eplislon=0.015917127532080494. Q_Delta=0.00865785619096085\n",
      "Episode 827 finished after 3 timesteps. Eplislon=0.01583754189442009. Q_Delta=0.0172583607896248\n",
      "Episode 828 finished after 1 timesteps. Eplislon=0.01575835418494799. Q_Delta=0.010676976160319152\n",
      "Episode 829 finished after 4 timesteps. Eplislon=0.01567956241402325. Q_Delta=0.006427898981893082\n",
      "Episode 830 finished after 2 timesteps. Eplislon=0.015601164601953134. Q_Delta=0.008921366472544878\n",
      "Episode 831 finished after 3 timesteps. Eplislon=0.015523158778943369. Q_Delta=0.01198626427927818\n",
      "Episode 832 finished after 1 timesteps. Eplislon=0.015445542985048652. Q_Delta=0.019090024911530334\n",
      "Episode 833 finished after 3 timesteps. Eplislon=0.015368315270123408. Q_Delta=0.007736867524582025\n",
      "Episode 834 finished after 5 timesteps. Eplislon=0.01529147369377279. Q_Delta=0.008926038268745207\n",
      "Episode 835 finished after 4 timesteps. Eplislon=0.015215016325303928. Q_Delta=0.005588105030786189\n",
      "Episode 836 finished after 2 timesteps. Eplislon=0.015138941243677408. Q_Delta=0.0031432032869490034\n",
      "Episode 837 finished after 3 timesteps. Eplislon=0.01506324653745902. Q_Delta=0.0030082352055209594\n",
      "Episode 838 finished after 2 timesteps. Eplislon=0.014987930304771725. Q_Delta=0.004317435775592182\n",
      "Episode 839 finished after 2 timesteps. Eplislon=0.014912990653247866. Q_Delta=0.02045734982288777\n",
      "Episode 840 finished after 4 timesteps. Eplislon=0.014838425699981627. Q_Delta=0.006356435146814193\n",
      "Episode 841 finished after 4 timesteps. Eplislon=0.01476423357148172. Q_Delta=0.00865093707146708\n",
      "Episode 842 finished after 1 timesteps. Eplislon=0.014690412403624311. Q_Delta=0.004051278260781999\n",
      "Episode 843 finished after 3 timesteps. Eplislon=0.01461696034160619. Q_Delta=0.002249520749491437\n",
      "Episode 844 finished after 3 timesteps. Eplislon=0.014543875539898159. Q_Delta=0.0012168640115356455\n",
      "Episode 845 finished after 5 timesteps. Eplislon=0.014471156162198668. Q_Delta=0.008085865646650037\n",
      "Episode 846 finished after 2 timesteps. Eplislon=0.014398800381387675. Q_Delta=0.002706896500289435\n",
      "Episode 847 finished after 1 timesteps. Eplislon=0.014326806379480736. Q_Delta=0.004978933429991672\n",
      "Episode 848 finished after 2 timesteps. Eplislon=0.014255172347583332. Q_Delta=0.006710872706767901\n",
      "Episode 849 finished after 7 timesteps. Eplislon=0.014183896485845416. Q_Delta=0.005194618977087189\n",
      "Episode 850 finished after 3 timesteps. Eplislon=0.014112977003416188. Q_Delta=0.0035347987924760535\n",
      "Episode 851 finished after 2 timesteps. Eplislon=0.014042412118399107. Q_Delta=0.004983543869187201\n",
      "Episode 852 finished after 2 timesteps. Eplislon=0.013972200057807112. Q_Delta=0.004351505233073039\n",
      "Episode 853 finished after 3 timesteps. Eplislon=0.013902339057518077. Q_Delta=0.0027045794095125197\n",
      "Episode 854 finished after 4 timesteps. Eplislon=0.013832827362230486. Q_Delta=0.011459592041047878\n",
      "Episode 855 finished after 2 timesteps. Eplislon=0.013763663225419333. Q_Delta=0.011185361552462969\n",
      "Episode 856 finished after 5 timesteps. Eplislon=0.013694844909292236. Q_Delta=0.00538391372296485\n",
      "Episode 857 finished after 5 timesteps. Eplislon=0.013626370684745774. Q_Delta=0.011260074088732641\n",
      "Episode 858 finished after 5 timesteps. Eplislon=0.013558238831322046. Q_Delta=0.002433893721387981\n",
      "Episode 859 finished after 3 timesteps. Eplislon=0.013490447637165436. Q_Delta=0.006831465579191416\n",
      "Episode 860 finished after 6 timesteps. Eplislon=0.013422995398979608. Q_Delta=0.006924873483061533\n",
      "Episode 861 finished after 4 timesteps. Eplislon=0.01335588042198471. Q_Delta=0.00518739872146573\n",
      "Episode 862 finished after 2 timesteps. Eplislon=0.013289101019874787. Q_Delta=0.005883795397755465\n",
      "Episode 863 finished after 1 timesteps. Eplislon=0.013222655514775413. Q_Delta=0.01052630387131881\n",
      "Episode 864 finished after 3 timesteps. Eplislon=0.013156542237201536. Q_Delta=0.007926769248073192\n",
      "Episode 865 finished after 2 timesteps. Eplislon=0.013090759526015528. Q_Delta=0.0037562767050458024\n",
      "Episode 866 finished after 1 timesteps. Eplislon=0.01302530572838545. Q_Delta=0.00237631298975316\n",
      "Episode 867 finished after 3 timesteps. Eplislon=0.012960179199743523. Q_Delta=0.005294290301083786\n",
      "Episode 868 finished after 4 timesteps. Eplislon=0.012895378303744804. Q_Delta=0.004646951796582449\n",
      "Episode 869 finished after 2 timesteps. Eplislon=0.01283090141222608. Q_Delta=0.004110963846992111\n",
      "Episode 870 finished after 6 timesteps. Eplislon=0.012766746905164949. Q_Delta=0.0034681230731889814\n",
      "Episode 871 finished after 1 timesteps. Eplislon=0.012702913170639124. Q_Delta=0.004359335499452888\n",
      "Episode 872 finished after 1 timesteps. Eplislon=0.012639398604785928. Q_Delta=0.0070928392543225804\n",
      "Episode 873 finished after 4 timesteps. Eplislon=0.012576201611761997. Q_Delta=0.0031634581941681894\n",
      "Episode 874 finished after 2 timesteps. Eplislon=0.012513320603703188. Q_Delta=0.0031090010916536293\n",
      "Episode 875 finished after 4 timesteps. Eplislon=0.012450754000684672. Q_Delta=0.004330287387655479\n",
      "Episode 876 finished after 5 timesteps. Eplislon=0.012388500230681249. Q_Delta=0.0031846401832298144\n",
      "Episode 877 finished after 1 timesteps. Eplislon=0.012326557729527843. Q_Delta=0.0035566671680453688\n",
      "Episode 878 finished after 6 timesteps. Eplislon=0.012264924940880204. Q_Delta=0.006199213389145086\n",
      "Episode 879 finished after 5 timesteps. Eplislon=0.012203600316175803. Q_Delta=0.002477134205636422\n",
      "Episode 880 finished after 3 timesteps. Eplislon=0.012142582314594924. Q_Delta=0.00624470410821291\n",
      "Episode 881 finished after 2 timesteps. Eplislon=0.01208186940302195. Q_Delta=0.0020922384481461553\n",
      "Episode 882 finished after 1 timesteps. Eplislon=0.01202146005600684. Q_Delta=0.002262725703132018\n",
      "Episode 883 finished after 4 timesteps. Eplislon=0.011961352755726806. Q_Delta=0.001959652307295251\n",
      "Episode 884 finished after 1 timesteps. Eplislon=0.01190154599194817. Q_Delta=0.0013075850827091173\n",
      "Episode 885 finished after 5 timesteps. Eplislon=0.01184203826198843. Q_Delta=0.0030403970494334853\n",
      "Episode 886 finished after 3 timesteps. Eplislon=0.011782828070678488. Q_Delta=0.002940470059910124\n",
      "Episode 887 finished after 4 timesteps. Eplislon=0.011723913930325095. Q_Delta=0.006899579955839147\n",
      "Episode 888 finished after 4 timesteps. Eplislon=0.01166529436067347. Q_Delta=0.005396901364533274\n",
      "Episode 889 finished after 5 timesteps. Eplislon=0.011606967888870102. Q_Delta=0.005257109964310702\n",
      "Episode 890 finished after 2 timesteps. Eplislon=0.01154893304942575. Q_Delta=0.005004785233273523\n",
      "Episode 891 finished after 1 timesteps. Eplislon=0.011491188384178622. Q_Delta=0.005611701975388739\n",
      "Episode 892 finished after 2 timesteps. Eplislon=0.011433732442257729. Q_Delta=0.001761951932184036\n",
      "Episode 893 finished after 3 timesteps. Eplislon=0.01137656378004644. Q_Delta=0.0015123380232590817\n",
      "Episode 894 finished after 3 timesteps. Eplislon=0.011319680961146208. Q_Delta=0.0038319674118250844\n",
      "Episode 895 finished after 2 timesteps. Eplislon=0.011263082556340478. Q_Delta=0.0019971507261660193\n",
      "Episode 896 finished after 6 timesteps. Eplislon=0.011206767143558775. Q_Delta=0.005021065167248595\n",
      "Episode 897 finished after 4 timesteps. Eplislon=0.011150733307840981. Q_Delta=0.001565096874253158\n",
      "Episode 898 finished after 1 timesteps. Eplislon=0.011094979641301777. Q_Delta=0.00301802400794271\n",
      "Episode 899 finished after 3 timesteps. Eplislon=0.011039504743095268. Q_Delta=0.0018998379115886532\n",
      "Episode 900 finished after 1 timesteps. Eplislon=0.01098430721937979. Q_Delta=0.006801062633752353\n",
      "Episode 901 finished after 2 timesteps. Eplislon=0.010929385683282892. Q_Delta=0.0009710210058384572\n",
      "Episode 902 finished after 2 timesteps. Eplislon=0.010874738754866477. Q_Delta=0.0013224969860300972\n",
      "Episode 903 finished after 3 timesteps. Eplislon=0.010820365061092144. Q_Delta=0.0021293351467286024\n",
      "Episode 904 finished after 5 timesteps. Eplislon=0.010766263235786683. Q_Delta=0.005840241877310337\n",
      "Episode 905 finished after 4 timesteps. Eplislon=0.01071243191960775. Q_Delta=0.0024311329210820742\n",
      "Episode 906 finished after 5 timesteps. Eplislon=0.010658869760009713. Q_Delta=0.005427679369625493\n",
      "Episode 907 finished after 4 timesteps. Eplislon=0.010605575411209664. Q_Delta=0.006886169143795168\n",
      "Episode 908 finished after 3 timesteps. Eplislon=0.010552547534153616. Q_Delta=0.0020545677139718332\n",
      "Episode 909 finished after 6 timesteps. Eplislon=0.010499784796482848. Q_Delta=0.0029783383750285144\n",
      "Episode 910 finished after 5 timesteps. Eplislon=0.010447285872500434. Q_Delta=0.005614923212491329\n",
      "Episode 911 finished after 2 timesteps. Eplislon=0.01039504944313793. Q_Delta=0.005738130783343787\n",
      "Episode 912 finished after 1 timesteps. Eplislon=0.010343074195922241. Q_Delta=0.007103060654745308\n",
      "Episode 913 finished after 2 timesteps. Eplislon=0.01029135882494263. Q_Delta=0.0035908187345954357\n",
      "Episode 914 finished after 1 timesteps. Eplislon=0.010239902030817916. Q_Delta=0.003956147937404175\n",
      "Episode 915 finished after 3 timesteps. Eplislon=0.010188702520663827. Q_Delta=0.0018665311043930544\n",
      "Episode 916 finished after 2 timesteps. Eplislon=0.010137759008060509. Q_Delta=0.003117978279317646\n",
      "Episode 917 finished after 4 timesteps. Eplislon=0.010087070213020206. Q_Delta=0.003423892092822678\n",
      "Episode 918 finished after 3 timesteps. Eplislon=0.010036634861955105. Q_Delta=0.004957930643327686\n",
      "Episode 919 finished after 4 timesteps. Eplislon=0.00998645168764533. Q_Delta=0.0023111838617045355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 920 finished after 3 timesteps. Eplislon=0.009936519429207103. Q_Delta=0.00164299734434592\n",
      "Episode 921 finished after 2 timesteps. Eplislon=0.009886836832061067. Q_Delta=0.001581027097098786\n",
      "Episode 922 finished after 2 timesteps. Eplislon=0.009837402647900761. Q_Delta=0.001755569542337243\n",
      "Episode 923 finished after 6 timesteps. Eplislon=0.009788215634661257. Q_Delta=0.0014150551475976363\n",
      "Episode 924 finished after 3 timesteps. Eplislon=0.00973927455648795. Q_Delta=0.0009132430291965606\n",
      "Episode 925 finished after 2 timesteps. Eplislon=0.009690578183705511. Q_Delta=0.0014000870182348524\n",
      "Episode 926 finished after 5 timesteps. Eplislon=0.009642125292786984. Q_Delta=0.0006566394594036184\n",
      "Episode 927 finished after 2 timesteps. Eplislon=0.009593914666323049. Q_Delta=0.001621002215896672\n",
      "Episode 928 finished after 2 timesteps. Eplislon=0.009545945092991434. Q_Delta=0.0007925335086186314\n",
      "Episode 929 finished after 3 timesteps. Eplislon=0.009498215367526477. Q_Delta=0.0006297905615617605\n",
      "Episode 930 finished after 3 timesteps. Eplislon=0.009450724290688845. Q_Delta=0.0008383717748119413\n",
      "Episode 931 finished after 5 timesteps. Eplislon=0.0094034706692354. Q_Delta=0.0008286775132434032\n",
      "Episode 932 finished after 2 timesteps. Eplislon=0.009356453315889223. Q_Delta=0.0008675876486977097\n",
      "Episode 933 finished after 4 timesteps. Eplislon=0.009309671049309777. Q_Delta=0.002597430999883521\n",
      "Episode 934 finished after 3 timesteps. Eplislon=0.009263122694063227. Q_Delta=0.0001844076739243213\n",
      "Episode 935 finished after 3 timesteps. Eplislon=0.009216807080592911. Q_Delta=0.0014996347520820723\n",
      "Episode 936 finished after 3 timesteps. Eplislon=0.009170723045189946. Q_Delta=0.00028662770149123773\n",
      "Episode 937 finished after 2 timesteps. Eplislon=0.009124869429963996. Q_Delta=0.0021527262259711244\n",
      "Episode 938 finished after 5 timesteps. Eplislon=0.009079245082814175. Q_Delta=0.00038973966727486877\n",
      "Episode 939 finished after 5 timesteps. Eplislon=0.009033848857400105. Q_Delta=0.006556189092699038\n",
      "Episode 940 finished after 3 timesteps. Eplislon=0.008988679613113105. Q_Delta=0.0032368371322184877\n",
      "Episode 941 finished after 3 timesteps. Eplislon=0.00894373621504754. Q_Delta=0.004405108664041424\n",
      "Episode 942 finished after 3 timesteps. Eplislon=0.008899017533972303. Q_Delta=0.004233428558829577\n",
      "Episode 943 finished after 2 timesteps. Eplislon=0.008854522446302441. Q_Delta=0.0024169570927501938\n",
      "Episode 944 finished after 2 timesteps. Eplislon=0.00881024983407093. Q_Delta=0.0013572763292187262\n",
      "Episode 945 finished after 6 timesteps. Eplislon=0.008766198584900575. Q_Delta=0.003331608209746225\n",
      "Episode 946 finished after 2 timesteps. Eplislon=0.008722367591976072. Q_Delta=0.002508400679110956\n",
      "Episode 947 finished after 4 timesteps. Eplislon=0.008678755754016191. Q_Delta=0.008005890572624186\n",
      "Episode 948 finished after 4 timesteps. Eplislon=0.00863536197524611. Q_Delta=0.004150736790764331\n",
      "Episode 949 finished after 2 timesteps. Eplislon=0.00859218516536988. Q_Delta=0.002102842887537426\n",
      "Episode 950 finished after 3 timesteps. Eplislon=0.00854922423954303. Q_Delta=0.002961672243516955\n",
      "Episode 951 finished after 3 timesteps. Eplislon=0.008506478118345316. Q_Delta=0.002126969649425677\n",
      "Episode 952 finished after 4 timesteps. Eplislon=0.008463945727753589. Q_Delta=0.006346811573908567\n",
      "Episode 953 finished after 2 timesteps. Eplislon=0.00842162599911482. Q_Delta=0.0020812761729180895\n",
      "Episode 954 finished after 4 timesteps. Eplislon=0.008379517869119247. Q_Delta=0.0032710723329978653\n",
      "Episode 955 finished after 3 timesteps. Eplislon=0.008337620279773651. Q_Delta=0.007234481136248953\n",
      "Episode 956 finished after 5 timesteps. Eplislon=0.008295932178374783. Q_Delta=0.0017900037671280567\n",
      "Episode 957 finished after 4 timesteps. Eplislon=0.008254452517482908. Q_Delta=0.005931349242355249\n",
      "Episode 958 finished after 1 timesteps. Eplislon=0.008213180254895494. Q_Delta=0.005182668091484266\n",
      "Episode 959 finished after 6 timesteps. Eplislon=0.008172114353621017. Q_Delta=0.0031117605739979424\n",
      "Episode 960 finished after 6 timesteps. Eplislon=0.008131253781852912. Q_Delta=0.0020203297308827492\n",
      "Episode 961 finished after 4 timesteps. Eplislon=0.008090597512943647. Q_Delta=0.00702168554942556\n",
      "Episode 962 finished after 3 timesteps. Eplislon=0.008050144525378928. Q_Delta=0.0021063975801373833\n",
      "Episode 963 finished after 3 timesteps. Eplislon=0.008009893802752034. Q_Delta=0.0024088658512326777\n",
      "Episode 964 finished after 2 timesteps. Eplislon=0.007969844333738273. Q_Delta=0.0036121129506008764\n",
      "Episode 965 finished after 4 timesteps. Eplislon=0.007929995112069581. Q_Delta=0.0044835875062018415\n",
      "Episode 966 finished after 4 timesteps. Eplislon=0.007890345136509233. Q_Delta=0.0023415219031497903\n",
      "Episode 967 finished after 3 timesteps. Eplislon=0.007850893410826686. Q_Delta=0.0017451635416508109\n",
      "Episode 968 finished after 4 timesteps. Eplislon=0.007811638943772553. Q_Delta=0.0018061882923992578\n",
      "Episode 969 finished after 3 timesteps. Eplislon=0.00777258074905369. Q_Delta=0.0010684995741247667\n",
      "Episode 970 finished after 1 timesteps. Eplislon=0.0077337178453084215. Q_Delta=0.0011331520070283485\n",
      "Episode 971 finished after 2 timesteps. Eplislon=0.0076950492560818795. Q_Delta=0.0006582629503575355\n",
      "Episode 972 finished after 3 timesteps. Eplislon=0.00765657400980147. Q_Delta=0.0003975166584669898\n",
      "Episode 973 finished after 2 timesteps. Eplislon=0.007618291139752462. Q_Delta=0.0004431962657731603\n",
      "Episode 974 finished after 2 timesteps. Eplislon=0.0075801996840537. Q_Delta=0.0002876272888521769\n",
      "Episode 975 finished after 4 timesteps. Eplislon=0.007542298685633431. Q_Delta=0.002040004246416205\n",
      "Episode 976 finished after 4 timesteps. Eplislon=0.007504587192205264. Q_Delta=0.0018379563768292917\n",
      "Episode 977 finished after 3 timesteps. Eplislon=0.0074670642562442375. Q_Delta=0.0016358492260670765\n",
      "Episode 978 finished after 5 timesteps. Eplislon=0.007429728934963016. Q_Delta=0.001881145797686856\n",
      "Episode 979 finished after 4 timesteps. Eplislon=0.007392580290288201. Q_Delta=0.0017706118157689577\n",
      "Episode 980 finished after 4 timesteps. Eplislon=0.00735561738883676. Q_Delta=0.002756425137312307\n",
      "Episode 981 finished after 5 timesteps. Eplislon=0.007318839301892576. Q_Delta=0.0013681238177307264\n",
      "Episode 982 finished after 3 timesteps. Eplislon=0.0072822451053831125. Q_Delta=0.001085187583125628\n",
      "Episode 983 finished after 2 timesteps. Eplislon=0.007245833879856197. Q_Delta=0.001934889000900386\n",
      "Episode 984 finished after 5 timesteps. Eplislon=0.007209604710456916. Q_Delta=0.0014569290117584011\n",
      "Episode 985 finished after 2 timesteps. Eplislon=0.0071735566869046315. Q_Delta=0.0021424761022344474\n",
      "Episode 986 finished after 2 timesteps. Eplislon=0.007137688903470108. Q_Delta=0.0006071444261090964\n",
      "Episode 987 finished after 5 timesteps. Eplislon=0.0071020004589527575. Q_Delta=0.001536773991920981\n",
      "Episode 988 finished after 4 timesteps. Eplislon=0.0070664904566579935. Q_Delta=0.0008439193833773284\n",
      "Episode 989 finished after 3 timesteps. Eplislon=0.007031158004374704. Q_Delta=0.0010630515802571387\n",
      "Episode 990 finished after 1 timesteps. Eplislon=0.00699600221435283. Q_Delta=0.0005989039738922841\n",
      "Episode 991 finished after 4 timesteps. Eplislon=0.0069610222032810655. Q_Delta=0.0015654512916914998\n",
      "Episode 992 finished after 2 timesteps. Eplislon=0.0069262170922646605. Q_Delta=0.0006286428674673328\n",
      "Episode 993 finished after 2 timesteps. Eplislon=0.006891586006803337. Q_Delta=0.0010841696850265592\n",
      "Episode 994 finished after 3 timesteps. Eplislon=0.006857128076769321. Q_Delta=0.0006289081765589918\n",
      "Episode 995 finished after 3 timesteps. Eplislon=0.006822842436385474. Q_Delta=0.0006217489242508201\n",
      "Episode 996 finished after 2 timesteps. Eplislon=0.006788728224203546. Q_Delta=0.000506241120232731\n",
      "Episode 997 finished after 4 timesteps. Eplislon=0.006754784583082528. Q_Delta=0.0018795394528630938\n",
      "Episode 998 finished after 5 timesteps. Eplislon=0.006721010660167116. Q_Delta=0.0007975055015264409\n",
      "Episode 999 finished after 2 timesteps. Eplislon=0.00668740560686628. Q_Delta=0.0007796748202368309\n",
      "Episode 1000 finished after 4 timesteps. Eplislon=0.006653968578831948. Q_Delta=0.0019613863945867616\n"
     ]
    }
   ],
   "source": [
    "train(epsilon_greedy_policy, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current estimates of q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.6158861 , 0.62582307, 0.62775117, 0.63344254],\n",
       "        [0.59492904, 0.64371173, 0.72779348, 0.76158336],\n",
       "        [0.63116915, 0.6493037 , 0.77441553, 0.81960775],\n",
       "        [0.64674917, 0.68068603, 0.82203199, 0.67465353]],\n",
       "\n",
       "       [[0.66970614, 0.74170172, 0.71648302, 0.74727872],\n",
       "        [0.6548344 , 0.73713401, 0.80110498, 0.90997436],\n",
       "        [0.67860998, 0.79380229, 0.979512  , 0.94932395],\n",
       "        [0.74961898, 0.89303597, 1.11797035, 0.8362021 ]],\n",
       "\n",
       "       [[0.59005972, 0.60746182, 0.58005861, 0.60399724],\n",
       "        [0.54453877, 0.58100982, 0.66956028, 0.69903702],\n",
       "        [0.54524714, 0.63031498, 0.75585223, 0.74375212],\n",
       "        [0.58360111, 0.65783605, 0.7621886 , 0.64929498]],\n",
       "\n",
       "       [[0.67290375, 0.73610613, 0.71822396, 0.76673053],\n",
       "        [0.62813164, 0.73591152, 0.86242113, 0.9477278 ],\n",
       "        [0.65914157, 0.80449378, 1.01969181, 1.12815753],\n",
       "        [0.67966637, 0.80821061, 1.01098999, 0.82250206]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Current estimates of q')\n",
    "q_table_viz(q_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 finished after 4 timesteps\n",
      "Episode 1 finished after 3 timesteps\n",
      "Episode 2 finished after 5 timesteps\n"
     ]
    }
   ],
   "source": [
    "visualise_agent(greedy_policy, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook!\n",
    "\n",
    "Next you might want to check out:\n",
    "- [Policy Gradients]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
